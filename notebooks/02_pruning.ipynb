{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6172af",
   "metadata": {},
   "source": [
    "# 2. Pruning\n",
    "\n",
    "This notebook demonstrates how to prune a model using the `torh.torch.nn.utils.prune` and `torch-pruning` library. Pruning is a technique to reduce the size of a neural network by removing weights that are deemed unnecessary, which can lead to faster inference times and reduced memory usage.\n",
    "\n",
    "There is 2 types of pruning:\n",
    "- **Unstructured pruning**: Removes individual weights using an importance metric (e.g., low-magnitude weights are pruned). This can lead to sparse models, which reduce drastically the number of parameters but must rely on specialized hardware and/or libraries to take advantage of the sparsity during inference.\n",
    "- **Structured pruning**: Removes entire channels or layers, using a metric measuring an entire channel or layer importance (e.g., low-magnitude channels are pruned). This leads to a more regular model that can be used on standard hardware without requiring specialized libraries.\n",
    "\n",
    "Metrics used for pruning are typically based on the magnitude of weights, gradients, or other statistics that indicate the importance of a weight or a channel.\n",
    "\n",
    "The process is defined as such:\n",
    "* A Torch model is loaded.\n",
    "* A pruning strategy is defined, which specifies how to prune the model (e.g., unstructured or structured pruning, and the importance metric to use).\n",
    "* The model is pruned using the defined strategy.\n",
    "* The model is exported PyTorch format for further optimization or deployment.\n",
    "\n",
    "2 pruning methods will be used in this notebook, both for 2 models (image and audio classification):\n",
    "* L1-magntiude unstructured pruning using `torch.torch.nn.utils.prune`.\n",
    "* L1-magnitude structured pruning using `torch-pruning`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405ace3",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b5e6b",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498b4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Callable, Literal\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from torch.optim import Optimizer\n",
    "from torch.amp import GradScaler, autocast\n",
    "import torch.nn.utils.prune as unstruct_prune\n",
    "import torch_pruning as struct_prune\n",
    "\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    pynvml_available = True\n",
    "except (ImportError, pynvml.NVMLError):\n",
    "    pynvml_available = False\n",
    "print(f\"pynvml available: {pynvml_available}\")\n",
    "\n",
    "# Setup device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "DTYPE = torch.bfloat16 if DEVICE == \"cuda\" else torch.float32\n",
    "\n",
    "# Base directories for datasets and models\n",
    "BASE_DATA_DIR = \"../data\"\n",
    "IMAGE_DATA_DIR = os.path.join(BASE_DATA_DIR, \"image\")\n",
    "BASE_MODEL_DIR = \"../models\"\n",
    "MODEL_BASELINE_DIR = os.path.join(BASE_MODEL_DIR, \"baseline\")\n",
    "\n",
    "# CIFAR-10 dataset directories\n",
    "CIFAR10_DIR = os.path.join(IMAGE_DATA_DIR, \"cifar10\")\n",
    "CIFAR10_TRAIN_DIR = os.path.join(CIFAR10_DIR, \"train\")\n",
    "CIFAR10_TRAIN_PT_FILE = os.path.join(CIFAR10_TRAIN_DIR, \"data.pt\")\n",
    "CIFAR10_VAL_DIR = os.path.join(CIFAR10_DIR, \"val\")\n",
    "CIFAR10_VAL_PT_FILE = os.path.join(CIFAR10_VAL_DIR, \"data.pt\")\n",
    "CIFAR10_TEST_DIR = os.path.join(CIFAR10_DIR, \"test\")\n",
    "CIFAR10_TEST_PT_FILE = os.path.join(CIFAR10_TEST_DIR, \"data.pt\")\n",
    "\n",
    "# MobileNetV2 model directory\n",
    "MOBILENETV2_CIFAR10_BASELINE_PT_FILE = os.path.join(MODEL_BASELINE_DIR, \"mobilenetv2_cifar10.pt\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b508f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127fa4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 13:05:51,220 - __main__ - INFO - MobileNetV2 model for CIFAR-10 loaded from state_dict and prepared on cuda.\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the base MobileNetV2 architecture\n",
    "# We use weights=None because we will load our own fine-tuned weights.\n",
    "mobilnet_v2_cifar10_base = torchvision.models.mobilenet_v2(weights=None)\n",
    "num_classes_cifar10 = 10\n",
    "\n",
    "# 2. Adapt the classifier head to match the CIFAR-10 adaptation (10 classes)\n",
    "# This is necessary so the architecture matches the saved state_dict.\n",
    "if hasattr(mobilnet_v2_cifar10_base, 'classifier') and isinstance(mobilnet_v2_cifar10_base.classifier, torch.nn.Sequential):\n",
    "    if hasattr(mobilnet_v2_cifar10_base.classifier[-1], 'in_features'):\n",
    "        in_features = mobilnet_v2_cifar10_base.classifier[-1].in_features\n",
    "        mobilnet_v2_cifar10_base.classifier[-1] = torch.nn.Linear(in_features, num_classes_cifar10)\n",
    "    else:\n",
    "        # This case should ideally not be hit if MobileNetV2 structure is standard\n",
    "        logger.error(\"Could not find 'in_features' in the last layer of the classifier to adapt.\")\n",
    "        raise AttributeError(\"Could not find 'in_features' in the last layer of the classifier.\")\n",
    "elif hasattr(mobilnet_v2_cifar10_base, 'fc'): # Fallback for models using 'fc'\n",
    "     in_features = mobilnet_v2_cifar10_base.fc.in_features\n",
    "     mobilnet_v2_cifar10_base.fc = torch.nn.Linear(in_features, num_classes_cifar10)\n",
    "else:\n",
    "    logger.error(\"Model does not have a known 'classifier' (Sequential) or 'fc' (Linear) attribute to adapt.\")\n",
    "    raise AttributeError(\"Model does not have a known classifier structure to adapt.\")\n",
    "\n",
    "# 3. Load the saved state_dict\n",
    "# The MOBILENETV2_CIFAR10_BASELINE_PT_FILE contains the state_dict.\n",
    "saved_state_dict = torch.load(MOBILENETV2_CIFAR10_BASELINE_PT_FILE, map_location=DEVICE)\n",
    "mobilnet_v2_cifar10_base.load_state_dict(saved_state_dict)\n",
    "\n",
    "# 4. Move model to the correct device and set to evaluation mode\n",
    "mobilnet_v2_cifar10_base.to(DEVICE)\n",
    "mobilnet_v2_cifar10_base.eval() # Important if you're not immediately training\n",
    "\n",
    "logger.info(f\"MobileNetV2 model for CIFAR-10 loaded from state_dict and prepared on {DEVICE}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ac093",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7a205",
   "metadata": {},
   "source": [
    "### L1 magnitude unstructured pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ea294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_weights_with_l1_unstructured_pruning(model: torch.nn.Module, \n",
    "                                  pruning_amount: float, \n",
    "                                  layers_to_prune: tuple = (torch.nn.Linear, torch.nn.Conv2d),\n",
    "                                  parameter_name: str = \"weight\") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Applies L1 unstructured pruning to specified layers of a model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to prune.\n",
    "        pruning_amount (float): The fraction of connections to prune (e.g., 0.2 for 20%).\n",
    "        layers_to_prune (tuple): A tuple of layer types to prune (e.g., (torch.nn.Linear, torch.nn.Conv2d)).\n",
    "        parameter_name (str): The name of the parameter to prune within the layers (e.g., \"weight\", \"bias\").\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The model with pruning applied (reparameterized).\n",
    "    \"\"\"\n",
    "    if not (0.0 < pruning_amount < 1.0):\n",
    "        raise ValueError(\"Pruning amount must be between 0.0 and 1.0 (exclusive).\")\n",
    "\n",
    "    logger.info(f\"Applying L1 unstructured pruning with amount: {pruning_amount:.2f} for parameter '{parameter_name}' in layers: {[layer.__name__ for layer in layers_to_prune]}\")\n",
    "    num_pruned_layers = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, layers_to_prune):\n",
    "            try:\n",
    "                unstruct_prune.l1_unstructured(module, name=parameter_name, amount=pruning_amount)\n",
    "                logger.debug(f\"Pruned {parameter_name} of layer: {module}\")\n",
    "                num_pruned_layers +=1\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not prune {parameter_name} of layer {module}: {e}\")\n",
    "    \n",
    "    if num_pruned_layers == 0:\n",
    "        logger.warning(\"No layers were pruned. Check 'layers_to_prune' and model structure.\")\n",
    "    else:\n",
    "        logger.info(f\"Applied L1 unstructured pruning to {num_pruned_layers} layers.\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def remove_pruning_reparameterization(model: torch.nn.Module,\n",
    "                                      layers_to_prune: tuple = (torch.nn.Linear, torch.nn.Conv2d),\n",
    "                                      parameter_name: str = \"weight\") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Removes the pruning reparameterization, making the pruning permanent.\n",
    "    The pruned weights are set to zero directly in the parameter tensor.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model with pruning applied.\n",
    "        layers_to_prune (tuple): A tuple of layer types from which to remove reparameterization.\n",
    "        parameter_name (str): The name of the parameter that was pruned.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The model with pruning made permanent.\n",
    "\n",
    "    Notes:\n",
    "        Must be called after `mark_weights_with_l1_unstructured_pruning`.\n",
    "    \"\"\"\n",
    "    logger.info(\"Making pruning permanent by removing reparameterization...\")\n",
    "    num_permanent_layers = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, layers_to_prune):\n",
    "            if unstruct_prune.is_pruned(module): # Check if the module has pruning hooks\n",
    "                try:\n",
    "                    unstruct_prune.remove(module, name=parameter_name)\n",
    "                    logger.debug(f\"Made pruning permanent for {parameter_name} of layer: {module}\")\n",
    "                    num_permanent_layers +=1\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not make pruning permanent for {parameter_name} of layer {module}: {e}\")\n",
    "            \n",
    "    if num_permanent_layers == 0:\n",
    "        logger.warning(\"No pruning reparameterization was removed. Was the model pruned?\")\n",
    "    else:\n",
    "        logger.info(f\"Made pruning permanent for {num_permanent_layers} layers.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_sparsity(model: torch.nn.Module, \n",
    "                       layers_to_check: tuple = (torch.nn.Linear, torch.nn.Conv2d),\n",
    "                       parameter_name: str = \"weight\") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates the sparsity of specified parameters in the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to check.\n",
    "        layers_to_check (tuple): Layer types to inspect.\n",
    "        parameter_name (str): Name of the parameter (e.g., \"weight\").\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: A dictionary containing overall sparsity and sparsity per layer.\n",
    "\n",
    "    Notes:\n",
    "        Must be applied after `mark_weights_with_l1_unstructured_pruning` and `remove_pruning_reparameterization`.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    total_zeros = 0\n",
    "    total_elements = 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, layers_to_check):\n",
    "            if hasattr(module, parameter_name):\n",
    "                param = getattr(module, parameter_name)\n",
    "                if param is not None:\n",
    "                    # If pruning is applied but not made permanent, the original tensor might not be zero.\n",
    "                    # We need to check the 'weight_orig' and 'weight_mask' if they exist.\n",
    "                    # However, if remove_pruning_reparameterization has been called,\n",
    "                    # the 'weight' tensor itself will contain zeros.\n",
    "                    \n",
    "                    # For simplicity after `remove`, we check the actual parameter.\n",
    "                    # If `remove` hasn't been called, this will report sparsity of the\n",
    "                    # underlying tensor before the mask is applied during forward pass.\n",
    "                    # For true sparsity *during* forward pass before `remove`, one would\n",
    "                    # need to access module.weight_mask and module.weight_orig.\n",
    "                    \n",
    "                    layer_zeros = torch.sum(param.data == 0).item()\n",
    "                    layer_elements = param.data.numel()\n",
    "                    total_zeros += layer_zeros\n",
    "                    total_elements += layer_elements\n",
    "                    if layer_elements > 0:\n",
    "                        layer_sparsity = layer_zeros / layer_elements\n",
    "                        results[f\"{name}.{parameter_name}_sparsity\"] = layer_sparsity\n",
    "                        logger.debug(f\"Sparsity of {name}.{parameter_name}: {layer_sparsity:.4f} ({layer_zeros}/{layer_elements})\")\n",
    "                    else:\n",
    "                        results[f\"{name}.{parameter_name}_sparsity\"] = 0.0\n",
    "                        logger.debug(f\"Layer {name}.{parameter_name} has 0 elements.\")\n",
    "\n",
    "\n",
    "    overall_sparsity = total_zeros / total_elements if total_elements > 0 else 0.0\n",
    "    results[\"overall_sparsity\"] = overall_sparsity\n",
    "    logger.info(f\"Overall sparsity ({parameter_name}): {overall_sparsity:.4f} ({total_zeros}/{total_elements})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def apply_l1_unstructured_pruning(model: torch.nn.Module, \n",
    "                                  pruning_amount: float, \n",
    "                                  layers_to_prune: tuple = (torch.nn.Linear, torch.nn.Conv2d),\n",
    "                                  parameter_name: str = \"weight\") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Applies L1 unstructured pruning to the model and returns the pruned model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to prune.\n",
    "        pruning_amount (float): The fraction of connections to prune.\n",
    "        layers_to_prune (tuple): Layers to apply pruning to.\n",
    "        parameter_name (str): The name of the parameter to prune.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The pruned model.\n",
    "    \"\"\"\n",
    "    model = mark_weights_with_l1_unstructured_pruning(model, pruning_amount, layers_to_prune, parameter_name)\n",
    "    model = remove_pruning_reparameterization(model, layers_to_prune, parameter_name)\n",
    "    logger.info(\"L1 unstructured pruning completed.\")\n",
    "    _ = calculate_sparsity(model, layers_to_prune, parameter_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4dca5",
   "metadata": {},
   "source": [
    "### L1 magnitude structured pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34916b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_parameters(model: torch.nn.Module, only_trainable: bool = True) -> int:\n",
    "    \"\"\"Counts the total number of parameters in a model.\"\"\"\n",
    "    if only_trainable:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def apply_l1_structured_pruning(\n",
    "    model: torch.nn.Module,\n",
    "    example_inputs: torch.Tensor,\n",
    "    pruning_amount: float,\n",
    "    layers_to_prune: tuple[type, ...] = (torch.nn.Conv2d, torch.nn.Linear),\n",
    "    ignored_layers: list[torch.nn.Module] | None = None,\n",
    "    prune_output_channels: bool = True\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Applies L1 magnitude structured pruning to specified layers of a model\n",
    "    by removing a fraction of channels/features from each targeted layer.\n",
    "\n",
    "    By default, it prunes output channels of Conv2d layers and output features\n",
    "    of Linear layers.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to prune.\n",
    "        example_inputs (torch.Tensor): A batch of example inputs for dependency tracing.\n",
    "                                       Should be on the same device as the model.\n",
    "        pruning_amount (float): The fraction of channels/features to prune from each\n",
    "                                targeted layer (e.g., 0.2 for 20%).\n",
    "        layers_to_prune (tuple[type, ...]): Tuple of layer types to prune.\n",
    "        ignored_layers (list[torch.nn.Module] | None): A list of specific layer\n",
    "                                                    modules to ignore during pruning.\n",
    "        prune_output_channels (bool): If True, prunes output channels/features.\n",
    "                                      If False, attempts to prune input channels/features\n",
    "                                      (Note: Input channel importance calculation here is simplified).\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The model with structured pruning applied. The model is modified in-place.\n",
    "    \"\"\"\n",
    "    if not (0.0 <= pruning_amount < 1.0):\n",
    "        raise ValueError(\"Pruning amount must be between 0.0 (inclusive) and 1.0 (exclusive).\")\n",
    "\n",
    "    if pruning_amount == 0.0:\n",
    "        logger.info(\"Pruning amount is 0.0. No structured pruning will be applied.\")\n",
    "        return model\n",
    "\n",
    "    # torch-pruning usually expects the model in eval mode for graph construction\n",
    "    original_mode_is_train = model.training\n",
    "    model.eval()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    example_inputs = example_inputs.to(device)\n",
    "\n",
    "    logger.info(f\"Applying L1 structured pruning with amount: {pruning_amount:.2f}\")\n",
    "    initial_params = count_model_parameters(model)\n",
    "    logger.info(f\"Initial model parameters: {initial_params}\")\n",
    "\n",
    "    DG = struct_prune.DependencyGraph()\n",
    "    DG.build_dependency(model, example_inputs=example_inputs)\n",
    "\n",
    "    num_pruned_overall_layers = 0\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, layers_to_prune):\n",
    "            if ignored_layers and module in ignored_layers:\n",
    "                logger.debug(f\"Skipping ignored layer: {name} ({type(module).__name__})\")\n",
    "                continue\n",
    "\n",
    "            current_channels = 0\n",
    "            pruning_fn = None\n",
    "            dim_type = \"\"\n",
    "            weights = module.weight.data\n",
    "\n",
    "            if prune_output_channels:\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    current_channels = module.out_channels\n",
    "                    pruning_fn = struct_prune.prune_conv_out_channels\n",
    "                    dim_type = \"output channels\"\n",
    "                    # L1 norm for each output filter: (C_out, C_in, K_h, K_w) -> sum over C_in, K_h, K_w\n",
    "                    channel_importance = torch.norm(weights.flatten(1), p=1, dim=1)\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    current_channels = module.out_features\n",
    "                    pruning_fn = struct_prune.prune_linear_out_features\n",
    "                    dim_type = \"output features\"\n",
    "                    # L1 norm for each output feature's weights: (F_out, F_in) -> sum over F_in\n",
    "                    channel_importance = torch.norm(weights, p=1, dim=1)\n",
    "                else: # Should not be reached if layers_to_prune is respected\n",
    "                    continue\n",
    "            else: # Pruning input channels\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    current_channels = module.in_channels\n",
    "                    pruning_fn = struct_prune.prune_conv_in_channels\n",
    "                    dim_type = \"input channels\"\n",
    "                    # Simplified L1 for input channels: (C_out, C_in, K_h, K_w) -> transpose to (C_in, C_out, K_h, K_w)\n",
    "                    channel_importance = torch.norm(weights.transpose(0,1).contiguous().flatten(1), p=1, dim=1)\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    current_channels = module.in_features\n",
    "                    pruning_fn = struct_prune.prune_linear_in_features\n",
    "                    dim_type = \"input features\"\n",
    "                    # Simplified L1 for input features: (F_out, F_in) -> transpose to (F_in, F_out)\n",
    "                    channel_importance = torch.norm(weights.T.contiguous(), p=1, dim=1)\n",
    "                else: # Should not be reached\n",
    "                    continue\n",
    "\n",
    "            if current_channels == 0:\n",
    "                logger.warning(f\"Layer {name} ({type(module).__name__}) has 0 {dim_type} to prune. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            num_to_prune = int(pruning_amount * current_channels)\n",
    "\n",
    "            if num_to_prune == 0:\n",
    "                logger.debug(f\"Layer {name}: No {dim_type} to prune with amount {pruning_amount:.2f} (Total: {current_channels}).\")\n",
    "                continue\n",
    "\n",
    "            # Ensure we don't prune all channels, as torch-pruning might error or lead to a dead network.\n",
    "            # It's safer to leave at least one channel.\n",
    "            if num_to_prune >= current_channels:\n",
    "                num_to_prune = current_channels - 1\n",
    "                logger.warning(\n",
    "                    f\"Layer {name}: Pruning amount {pruning_amount:.2f} would remove all or too many {dim_type}. \"\n",
    "                    f\"Adjusting to prune {num_to_prune} {dim_type} to keep at least one.\"\n",
    "                )\n",
    "                if num_to_prune <= 0: # If current_channels was 1\n",
    "                    logger.info(f\"Layer {name}: Cannot prune, only 1 {dim_type} exists. Skipping.\")\n",
    "                    continue\n",
    "            \n",
    "            # Get indices of channels to prune (those with smallest L1 norm)\n",
    "            sorted_channel_indices = torch.argsort(channel_importance)\n",
    "            pruning_indices = sorted_channel_indices[:num_to_prune].tolist()\n",
    "\n",
    "            try:\n",
    "                pruning_plan = DG.get_pruning_plan(module, pruning_fn, idxs=pruning_indices)\n",
    "                if pruning_plan:\n",
    "                    logger.debug(f\"Pruning {num_to_prune} {dim_type} from layer {name} ({type(module).__name__}). Smallest L1 norm indices (first 10): {pruning_indices[:10]}...\")\n",
    "                    pruning_plan.exec()\n",
    "                    num_pruned_overall_layers += 1\n",
    "                else:\n",
    "                    logger.warning(f\"Could not generate pruning plan for layer {name} ({type(module).__name__}).\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to prune layer {name} ({type(module).__name__}): {e}\", exc_info=True)\n",
    "\n",
    "    if num_pruned_overall_layers == 0:\n",
    "        logger.warning(\"No layers were structurally pruned. Check 'layers_to_prune', model structure, and pruning_amount.\")\n",
    "    else:\n",
    "        logger.info(f\"Applied structured pruning to {num_pruned_overall_layers} layers.\")\n",
    "\n",
    "    final_params = count_model_parameters(model)\n",
    "    logger.info(f\"Final model parameters after structured pruning: {final_params}\")\n",
    "    if initial_params > 0 :\n",
    "        reduction_percent = (initial_params - final_params) / initial_params * 100\n",
    "        logger.info(f\"Parameter reduction: {initial_params - final_params} ({reduction_percent:.2f}%)\")\n",
    "    else:\n",
    "        logger.info(f\"Parameter reduction: {initial_params - final_params}\")\n",
    "\n",
    "\n",
    "    if original_mode_is_train:\n",
    "        model.train() # Set back to original mode\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0356a",
   "metadata": {},
   "source": [
    "# L1 unstructured pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53db271",
   "metadata": {},
   "source": [
    "## One-step pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe872f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 13:05:54,967 - __main__ - INFO - Applying L1 unstructured pruning with amount: 0.20 for parameter 'weight' in layers: ['Linear', 'Conv2d']\n",
      "2025-06-10 13:05:55,141 - __main__ - DEBUG - Pruned weight of layer: Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,142 - __main__ - DEBUG - Pruned weight of layer: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "2025-06-10 13:05:55,143 - __main__ - DEBUG - Pruned weight of layer: Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,144 - __main__ - DEBUG - Pruned weight of layer: Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,144 - __main__ - DEBUG - Pruned weight of layer: Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "2025-06-10 13:05:55,145 - __main__ - DEBUG - Pruned weight of layer: Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,146 - __main__ - DEBUG - Pruned weight of layer: Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,146 - __main__ - DEBUG - Pruned weight of layer: Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "2025-06-10 13:05:55,147 - __main__ - DEBUG - Pruned weight of layer: Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,148 - __main__ - DEBUG - Pruned weight of layer: Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,149 - __main__ - DEBUG - Pruned weight of layer: Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "2025-06-10 13:05:55,149 - __main__ - DEBUG - Pruned weight of layer: Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,150 - __main__ - DEBUG - Pruned weight of layer: Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,151 - __main__ - DEBUG - Pruned weight of layer: Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "2025-06-10 13:05:55,152 - __main__ - DEBUG - Pruned weight of layer: Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,152 - __main__ - DEBUG - Pruned weight of layer: Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,153 - __main__ - DEBUG - Pruned weight of layer: Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "2025-06-10 13:05:55,154 - __main__ - DEBUG - Pruned weight of layer: Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,155 - __main__ - DEBUG - Pruned weight of layer: Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,156 - __main__ - DEBUG - Pruned weight of layer: Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "2025-06-10 13:05:55,157 - __main__ - DEBUG - Pruned weight of layer: Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,240 - __main__ - DEBUG - Pruned weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,241 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,242 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,243 - __main__ - DEBUG - Pruned weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,243 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,244 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,245 - __main__ - DEBUG - Pruned weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,246 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,247 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,248 - __main__ - DEBUG - Pruned weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,249 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,250 - __main__ - DEBUG - Pruned weight of layer: Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,251 - __main__ - DEBUG - Pruned weight of layer: Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,251 - __main__ - DEBUG - Pruned weight of layer: Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "2025-06-10 13:05:55,252 - __main__ - DEBUG - Pruned weight of layer: Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,253 - __main__ - DEBUG - Pruned weight of layer: Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,254 - __main__ - DEBUG - Pruned weight of layer: Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "2025-06-10 13:05:55,255 - __main__ - DEBUG - Pruned weight of layer: Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,256 - __main__ - DEBUG - Pruned weight of layer: Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,257 - __main__ - DEBUG - Pruned weight of layer: Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "2025-06-10 13:05:55,259 - __main__ - DEBUG - Pruned weight of layer: Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,260 - __main__ - DEBUG - Pruned weight of layer: Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,261 - __main__ - DEBUG - Pruned weight of layer: Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "2025-06-10 13:05:55,262 - __main__ - DEBUG - Pruned weight of layer: Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,263 - __main__ - DEBUG - Pruned weight of layer: Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,264 - __main__ - DEBUG - Pruned weight of layer: Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "2025-06-10 13:05:55,266 - __main__ - DEBUG - Pruned weight of layer: Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,266 - __main__ - DEBUG - Pruned weight of layer: Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,267 - __main__ - DEBUG - Pruned weight of layer: Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "2025-06-10 13:05:55,269 - __main__ - DEBUG - Pruned weight of layer: Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,270 - __main__ - DEBUG - Pruned weight of layer: Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,271 - __main__ - DEBUG - Pruned weight of layer: Linear(in_features=1280, out_features=10, bias=True)\n",
      "2025-06-10 13:05:55,271 - __main__ - INFO - Applied L1 unstructured pruning to 53 layers.\n",
      "2025-06-10 13:05:55,272 - __main__ - INFO - Making pruning permanent by removing reparameterization...\n",
      "2025-06-10 13:05:55,272 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,273 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "2025-06-10 13:05:55,274 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,274 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,275 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "2025-06-10 13:05:55,275 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,276 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,276 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "2025-06-10 13:05:55,277 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,277 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,278 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "2025-06-10 13:05:55,278 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,279 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,280 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "2025-06-10 13:05:55,281 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,281 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,282 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "2025-06-10 13:05:55,282 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,283 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,283 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "2025-06-10 13:05:55,284 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,284 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,285 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,286 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,286 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,287 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,287 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,288 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,288 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,289 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,289 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,290 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "2025-06-10 13:05:55,290 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,291 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,291 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "2025-06-10 13:05:55,292 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,292 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,293 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "2025-06-10 13:05:55,294 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,294 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,295 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "2025-06-10 13:05:55,295 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,296 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,296 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "2025-06-10 13:05:55,297 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,298 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,298 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "2025-06-10 13:05:55,299 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,299 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,300 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "2025-06-10 13:05:55,300 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,301 - __main__ - DEBUG - Made pruning permanent for weight of layer: Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2025-06-10 13:05:55,302 - __main__ - DEBUG - Made pruning permanent for weight of layer: Linear(in_features=1280, out_features=10, bias=True)\n",
      "2025-06-10 13:05:55,302 - __main__ - INFO - Made pruning permanent for 53 layers.\n",
      "2025-06-10 13:05:55,303 - __main__ - INFO - L1 unstructured pruning completed.\n",
      "2025-06-10 13:05:55,386 - __main__ - DEBUG - Sparsity of features.0.0.weight: 0.2002 (173/864)\n",
      "2025-06-10 13:05:55,387 - __main__ - DEBUG - Sparsity of features.1.conv.0.0.weight: 0.2014 (58/288)\n",
      "2025-06-10 13:05:55,388 - __main__ - DEBUG - Sparsity of features.1.conv.1.weight: 0.1992 (102/512)\n",
      "2025-06-10 13:05:55,389 - __main__ - DEBUG - Sparsity of features.2.conv.0.0.weight: 0.1999 (307/1536)\n",
      "2025-06-10 13:05:55,389 - __main__ - DEBUG - Sparsity of features.2.conv.1.0.weight: 0.2002 (173/864)\n",
      "2025-06-10 13:05:55,390 - __main__ - DEBUG - Sparsity of features.2.conv.2.weight: 0.2001 (461/2304)\n",
      "2025-06-10 13:05:55,390 - __main__ - DEBUG - Sparsity of features.3.conv.0.0.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,391 - __main__ - DEBUG - Sparsity of features.3.conv.1.0.weight: 0.1998 (259/1296)\n",
      "2025-06-10 13:05:55,392 - __main__ - DEBUG - Sparsity of features.3.conv.2.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,392 - __main__ - DEBUG - Sparsity of features.4.conv.0.0.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,393 - __main__ - DEBUG - Sparsity of features.4.conv.1.0.weight: 0.1998 (259/1296)\n",
      "2025-06-10 13:05:55,393 - __main__ - DEBUG - Sparsity of features.4.conv.2.weight: 0.2001 (922/4608)\n",
      "2025-06-10 13:05:55,394 - __main__ - DEBUG - Sparsity of features.5.conv.0.0.weight: 0.2000 (1229/6144)\n",
      "2025-06-10 13:05:55,394 - __main__ - DEBUG - Sparsity of features.5.conv.1.0.weight: 0.2002 (346/1728)\n",
      "2025-06-10 13:05:55,395 - __main__ - DEBUG - Sparsity of features.5.conv.2.weight: 0.2000 (1229/6144)\n",
      "2025-06-10 13:05:55,396 - __main__ - DEBUG - Sparsity of features.6.conv.0.0.weight: 0.2000 (1229/6144)\n",
      "2025-06-10 13:05:55,396 - __main__ - DEBUG - Sparsity of features.6.conv.1.0.weight: 0.2002 (346/1728)\n",
      "2025-06-10 13:05:55,397 - __main__ - DEBUG - Sparsity of features.6.conv.2.weight: 0.2000 (1229/6144)\n",
      "2025-06-10 13:05:55,397 - __main__ - DEBUG - Sparsity of features.7.conv.0.0.weight: 0.2000 (1229/6144)\n",
      "2025-06-10 13:05:55,398 - __main__ - DEBUG - Sparsity of features.7.conv.1.0.weight: 0.2002 (346/1728)\n",
      "2025-06-10 13:05:55,398 - __main__ - DEBUG - Sparsity of features.7.conv.2.weight: 0.2000 (2458/12288)\n",
      "2025-06-10 13:05:55,399 - __main__ - DEBUG - Sparsity of features.8.conv.0.0.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,400 - __main__ - DEBUG - Sparsity of features.8.conv.1.0.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,400 - __main__ - DEBUG - Sparsity of features.8.conv.2.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,401 - __main__ - DEBUG - Sparsity of features.9.conv.0.0.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,402 - __main__ - DEBUG - Sparsity of features.9.conv.1.0.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,403 - __main__ - DEBUG - Sparsity of features.9.conv.2.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,403 - __main__ - DEBUG - Sparsity of features.10.conv.0.0.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,404 - __main__ - DEBUG - Sparsity of features.10.conv.1.0.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,404 - __main__ - DEBUG - Sparsity of features.10.conv.2.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,405 - __main__ - DEBUG - Sparsity of features.11.conv.0.0.weight: 0.2000 (4915/24576)\n",
      "2025-06-10 13:05:55,406 - __main__ - DEBUG - Sparsity of features.11.conv.1.0.weight: 0.1999 (691/3456)\n",
      "2025-06-10 13:05:55,406 - __main__ - DEBUG - Sparsity of features.11.conv.2.weight: 0.2000 (7373/36864)\n",
      "2025-06-10 13:05:55,407 - __main__ - DEBUG - Sparsity of features.12.conv.0.0.weight: 0.2000 (11059/55296)\n",
      "2025-06-10 13:05:55,407 - __main__ - DEBUG - Sparsity of features.12.conv.1.0.weight: 0.2000 (1037/5184)\n",
      "2025-06-10 13:05:55,408 - __main__ - DEBUG - Sparsity of features.12.conv.2.weight: 0.2000 (11059/55296)\n",
      "2025-06-10 13:05:55,408 - __main__ - DEBUG - Sparsity of features.13.conv.0.0.weight: 0.2000 (11059/55296)\n",
      "2025-06-10 13:05:55,409 - __main__ - DEBUG - Sparsity of features.13.conv.1.0.weight: 0.2000 (1037/5184)\n",
      "2025-06-10 13:05:55,410 - __main__ - DEBUG - Sparsity of features.13.conv.2.weight: 0.2000 (11059/55296)\n",
      "2025-06-10 13:05:55,411 - __main__ - DEBUG - Sparsity of features.14.conv.0.0.weight: 0.2000 (11059/55296)\n",
      "2025-06-10 13:05:55,411 - __main__ - DEBUG - Sparsity of features.14.conv.1.0.weight: 0.2000 (1037/5184)\n",
      "2025-06-10 13:05:55,412 - __main__ - DEBUG - Sparsity of features.14.conv.2.weight: 0.2000 (18432/92160)\n",
      "2025-06-10 13:05:55,412 - __main__ - DEBUG - Sparsity of features.15.conv.0.0.weight: 0.2000 (30720/153600)\n",
      "2025-06-10 13:05:55,413 - __main__ - DEBUG - Sparsity of features.15.conv.1.0.weight: 0.2000 (1728/8640)\n",
      "2025-06-10 13:05:55,414 - __main__ - DEBUG - Sparsity of features.15.conv.2.weight: 0.2000 (30720/153600)\n",
      "2025-06-10 13:05:55,414 - __main__ - DEBUG - Sparsity of features.16.conv.0.0.weight: 0.2000 (30720/153600)\n",
      "2025-06-10 13:05:55,415 - __main__ - DEBUG - Sparsity of features.16.conv.1.0.weight: 0.2000 (1728/8640)\n",
      "2025-06-10 13:05:55,415 - __main__ - DEBUG - Sparsity of features.16.conv.2.weight: 0.2000 (30720/153600)\n",
      "2025-06-10 13:05:55,416 - __main__ - DEBUG - Sparsity of features.17.conv.0.0.weight: 0.2000 (30720/153600)\n",
      "2025-06-10 13:05:55,416 - __main__ - DEBUG - Sparsity of features.17.conv.1.0.weight: 0.2000 (1728/8640)\n",
      "2025-06-10 13:05:55,417 - __main__ - DEBUG - Sparsity of features.17.conv.2.weight: 0.2000 (61440/307200)\n",
      "2025-06-10 13:05:55,418 - __main__ - DEBUG - Sparsity of features.18.0.weight: 0.2000 (81920/409600)\n",
      "2025-06-10 13:05:55,418 - __main__ - DEBUG - Sparsity of classifier.1.weight: 0.2000 (2560/12800)\n",
      "2025-06-10 13:05:55,419 - __main__ - INFO - Overall sparsity (weight): 0.2000 (440512/2202560)\n"
     ]
    }
   ],
   "source": [
    "# Apply L1 unstructured pruning to the MobileNetV2 model\n",
    "mobilnet_v2_cifar10_unstruct_prune = apply_l1_unstructured_pruning(mobilnet_v2_cifar10_base, pruning_amount=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293e56e",
   "metadata": {},
   "source": [
    "## Iterative pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64bcd3",
   "metadata": {},
   "source": [
    "# L1 structured pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1526e9",
   "metadata": {},
   "source": [
    "## One-step pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9aab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 13:06:07,582 - __main__ - INFO - Applying L1 structured pruning with amount: 0.20\n",
      "2025-06-10 13:06:07,583 - __main__ - INFO - Initial model parameters: 2236682\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (CUDABFloat16Type) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch_pruning/dependency.py:783\u001b[39m, in \u001b[36mDependencyGraph._trace\u001b[39m\u001b[34m(self, model, example_inputs, forward_fn, output_transform)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:174\u001b[39m, in \u001b[36mMobileNetV2.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:166\u001b[39m, in \u001b[36mMobileNetV2._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (CUDABFloat16Type) and weight type (torch.cuda.FloatTensor) should be the same",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mobilnet_v2_cifar10_struct_prune = \u001b[43mapply_l1_structured_pruning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmobilnet_v2_cifar10_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpruning_amount\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayers_to_prune\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprune_output_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mapply_l1_structured_pruning\u001b[39m\u001b[34m(model, example_inputs, pruning_amount, layers_to_prune, ignored_layers, prune_output_channels)\u001b[39m\n\u001b[32m     54\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitial model parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m DG = struct_prune.DependencyGraph()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mDG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m num_pruned_overall_layers = \u001b[32m0\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m model.named_modules():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch_pruning/dependency.py:386\u001b[39m, in \u001b[36mDependencyGraph.build_dependency\u001b[39m\u001b[34m(self, model, example_inputs, forward_fn, output_transform, unwrapped_parameters, customized_pruners, ignored_layers, ignored_params, verbose)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m torch.is_grad_enabled(), \u001b[33m\"\u001b[39m\u001b[33mDependency graph relies on autograd for tracing. Please check and disable the torch.no_grad() in your code.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;66;03m# Build computational graph through tracing. \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28mself\u001b[39m.module2node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_transform\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# Build dependency graph\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[38;5;28mself\u001b[39m._build_dependency(\u001b[38;5;28mself\u001b[39m.module2node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch_pruning/dependency.py:785\u001b[39m, in \u001b[36mDependencyGraph._trace\u001b[39m\u001b[34m(self, model, example_inputs, forward_fn, output_transform)\u001b[39m\n\u001b[32m    783\u001b[39m         out = model(*example_inputs)\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[32m    787\u001b[39m     hook.remove()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:174\u001b[39m, in \u001b[36mMobileNetV2.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:166\u001b[39m, in \u001b[36mMobileNetV2._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001b[39;00m\n\u001b[32m    168\u001b[39m     x = nn.functional.adaptive_avg_pool2d(x, (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/nnopt/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (CUDABFloat16Type) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "mobilnet_v2_cifar10_struct_prune = apply_l1_structured_pruning(\n",
    "    mobilnet_v2_cifar10_base,\n",
    "    example_inputs=torch.randn(1, 3, 224, 224, device=DEVICE, dtype=DTYPE),\n",
    "    pruning_amount=0.2,\n",
    "    layers_to_prune=(torch.nn.Conv2d, torch.nn.Linear),\n",
    "    prune_output_channels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73b7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
