{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b634e",
   "metadata": {},
   "source": [
    "# Data & Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571044d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084b2aa",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effcbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml available: True\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Literal\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from torch.optim import Optimizer\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    pynvml_available = True\n",
    "except (ImportError, pynvml.NVMLError):\n",
    "    pynvml_available = False\n",
    "print(f\"pynvml available: {pynvml_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ef47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de771fc",
   "metadata": {},
   "source": [
    "### Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop function\n",
    "def train_loop(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    epochs: int,\n",
    "    criterion: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    optimizer: Optimizer,\n",
    "    device: Literal[\"cpu\", \"cuda\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_amp: bool = True, \n",
    "    dtype: torch.dtype = torch.bfloat16 \n",
    "):\n",
    "    model.to(device)\n",
    "    \n",
    "    scaler = GradScaler(device, enabled=(use_amp and device == \"cuda\"))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train step\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\")\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type=device, enabled=(use_amp and device == \"cuda\"), dtype=dtype if device == \"cuda\" else None):\n",
    "                outputs = model(inputs)\n",
    "                loss: torch.Tensor = criterion(outputs, labels)\n",
    "            \n",
    "            if device == \"cuda\" and use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else: \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with autocast(device_type=device, enabled=(use_amp and device == \"cuda\"), dtype=dtype if device == \"cuda\" else None):\n",
    "                    outputs: torch.Tensor = model(inputs)\n",
    "                    loss_val: torch.Tensor = criterion(outputs, labels) \n",
    "                \n",
    "                val_loss += loss_val.item() \n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                val_pbar.set_postfix(loss=loss_val.item(), acc=correct/total_samples if total_samples > 0 else 0)\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        # System stats reporting\n",
    "        cpu_usage = psutil.cpu_percent()\n",
    "        ram_usage = psutil.virtual_memory().percent\n",
    "        stats_msg = f\"CPU Usage: {cpu_usage:.2f}% | RAM Usage: {ram_usage:.2f}%\"\n",
    "\n",
    "        if device == \"cuda\" and pynvml_available and torch.cuda.is_available():\n",
    "            try:\n",
    "                # Assuming a single GPU is being used or you want stats for GPU 0\n",
    "                gpu_id = torch.cuda.current_device() \n",
    "                handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)\n",
    "                gpu_util = pynvml.nvmlDeviceGetUtilizationRates(handle).gpu\n",
    "                mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                gpu_mem_usage = mem_info.used / mem_info.total * 100\n",
    "                stats_msg += f\" | GPU {gpu_id} Util: {gpu_util:.2f}% | GPU {gpu_id} Mem: {gpu_mem_usage:.2f}%\"\n",
    "            except pynvml.NVMLError as e:\n",
    "                stats_msg += f\" | GPU Stats Error: {e}\"\n",
    "        \n",
    "        tqdm.write(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f} | {stats_msg}\")\n",
    "\n",
    "\n",
    "# Function to adapt a classification model to a new dataset as such:\n",
    "# * Load the pretrained model from torchvision or torchaudio\n",
    "# * Replace the final layer to match the number of classes in the new dataset\n",
    "# * Train the head of the model with the backbone freezed on the new dataset\n",
    "# * After training the head, unfreeze the backbone and fine-tune the entire model\n",
    "# * Augment the dataset with random transformations\n",
    "def adapt_model_head_to_dataset(\n",
    "    model: torch.nn.Module, \n",
    "    num_classes: int, \n",
    "    train_dataset: torch.utils.data.Dataset, \n",
    "    val_dataset: torch.utils.data.Dataset,\n",
    "    batch_size: int = 32,\n",
    "    shuffle: bool = True,\n",
    "    num_workers: int = 4,\n",
    "    pin_memory: bool = True,\n",
    "    head_train_epochs: int = 10,\n",
    "    fine_tune_epochs: int = 5,\n",
    "    optimizer_cls: type[Optimizer] = torch.optim.Adam, # Changed to optimizer_cls\n",
    "    head_train_lr: float = 0.001,\n",
    "    fine_tune_lr: float = 0.0001,\n",
    "    device: Literal[\"cpu\", \"cuda\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_amp: bool = True,\n",
    "    dtype: torch.dtype = torch.bfloat16\n",
    ") -> torch.nn.Module:\n",
    "\n",
    "    # Replace the final layer\n",
    "    if hasattr(model, 'fc'):\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif hasattr(model, 'classifier') and isinstance(model.classifier, torch.nn.Sequential):\n",
    "        # Common case for models like MobileNetV2, EfficientNet\n",
    "        if hasattr(model.classifier[-1], 'in_features'):\n",
    "            model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "        else:\n",
    "            # Fallback for other structures if needed, this might require specific handling\n",
    "            logger.warning(f\"Warning: Classifier final layer replacement might be inexact.\")\n",
    "            # Attempt to find the last linear layer if possible, or raise error\n",
    "            for i in range(len(model.classifier) -1, -1, -1):\n",
    "                if isinstance(model.classifier[i], torch.nn.Linear):\n",
    "                    model.classifier[i] = torch.nn.Linear(model.classifier[i].in_features, num_classes)\n",
    "                    break\n",
    "            else:\n",
    "                raise AttributeError(f\"Could not find a final Linear layer in classifier\")\n",
    "\n",
    "    elif hasattr(model, 'classifier') and isinstance(model.classifier, torch.nn.Linear): # e.g. some ViT models\n",
    "        model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "    else:\n",
    "        raise AttributeError(f\"Model does not have 'fc' or a known 'classifier' structure to replace.\")\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=shuffle, \n",
    "                                               num_workers=num_workers, \n",
    "                                               pin_memory=pin_memory)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size, \n",
    "                                             shuffle=False, \n",
    "                                             num_workers=num_workers, \n",
    "                                             pin_memory=pin_memory)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Train the head ---\n",
    "    logger.info(\"Training head of the model with backbone frozen...\")\n",
    "    # Freeze the backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze the final layer (fc or classifier)\n",
    "    if hasattr(model, 'fc'):\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif hasattr(model, 'classifier'):\n",
    "        for param in model.classifier.parameters(): # Unfreeze all params in the classifier block\n",
    "            param.requires_grad = True\n",
    "    else: # Should not happen due to checks above\n",
    "        raise AttributeError(\"Final layer not found for unfreezing.\")\n",
    "\n",
    "    optimizer_head = optimizer_cls(filter(lambda p: p.requires_grad, model.parameters()), lr=head_train_lr)\n",
    "    \n",
    "    train_loop(model, train_loader, val_loader, head_train_epochs, criterion, optimizer_head, device, use_amp, dtype)\n",
    "\n",
    "    # --- Fine-tune the entire model ---\n",
    "    logger.info(\"Fine-tuning full model...\")\n",
    "    # Unfreeze the backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer_finetune = optimizer_cls(model.parameters(), lr=fine_tune_lr)\n",
    "\n",
    "    train_loop(model, train_loader, val_loader, fine_tune_epochs, criterion, optimizer_finetune, device, use_amp, dtype)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153aeb3",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d6232",
   "metadata": {},
   "source": [
    "### Image Processing Model\n",
    "* Task: Image classification\n",
    "* Model: MobileNetV2\n",
    "* Dataset: CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000663ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 model\n",
    "mobilnet_v2 = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "# CIFAR-10 dataset transforms for MobileNetV2\n",
    "image_train_cifar10_mobilenetV2_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Use ImageNet means/stds\n",
    "])\n",
    "image_val_cifar10_mobilenetV2_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Use ImageNet means/stds\n",
    "])\n",
    "\n",
    "# CIFAR-10 datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data/image/cifar10/train\",\n",
    "    train=True,\n",
    "    transform=image_train_cifar10_mobilenetV2_transform,\n",
    "    download=True\n",
    ")\n",
    "val_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data/image/cifar10/test\",\n",
    "    train=False,\n",
    "    transform=image_val_cifar10_mobilenetV2_transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75facaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 22:35:56,537 - __main__ - INFO - Training head of the model with backbone frozen...\n",
      "Epoch 1/5 [Training]:   0%|          | 0/782 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "autocast.__init__() missing 1 required positional argument: 'device_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Adapt the MobileNetV2 model to CIFAR-10 dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m adapted_model = \u001b[43madapt_model_head_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmobilnet_v2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# CIFAR-10 has 10 classes\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust batch size as needed\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Train head for fewer epochs\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfine_tune_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Fine-tune for fewer epochs\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use Adam optimizer\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_train_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Learning rate for head training\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfine_tune_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Learning rate for fine-tuning\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 169\u001b[39m, in \u001b[36madapt_model_head_to_dataset\u001b[39m\u001b[34m(model, num_classes, train_dataset, val_dataset, batch_size, shuffle, num_workers, pin_memory, head_train_epochs, fine_tune_epochs, optimizer_cls, head_train_lr, fine_tune_lr, device, use_amp, dtype)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFinal layer not found for unfreezing.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    167\u001b[39m optimizer_head = optimizer_cls(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p: p.requires_grad, model.parameters()), lr=head_train_lr)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_train_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# --- Fine-tune the entire model ---\u001b[39;00m\n\u001b[32m    172\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mFine-tuning full model...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, criterion, optimizer, device, use_amp, dtype)\u001b[39m\n\u001b[32m     23\u001b[39m inputs, labels = inputs.to(device), labels.to(device)\n\u001b[32m     25\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[32m     28\u001b[39m     outputs = model(inputs)\n\u001b[32m     29\u001b[39m     loss: torch.Tensor = criterion(outputs, labels)\n",
      "\u001b[31mTypeError\u001b[39m: autocast.__init__() missing 1 required positional argument: 'device_type'"
     ]
    }
   ],
   "source": [
    "# Adapt the MobileNetV2 model to CIFAR-10 dataset\n",
    "adapted_model = adapt_model_head_to_dataset(\n",
    "    model=mobilnet_v2,\n",
    "    num_classes=10,  # CIFAR-10 has 10 classes\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    head_train_epochs=5,  # Train head for fewer epochs\n",
    "    fine_tune_epochs=3,  # Fine-tune for fewer epochs\n",
    "    optimizer_cls=torch.optim.Adam,  # Use Adam optimizer\n",
    "    head_train_lr=0.001,  # Learning rate for head training\n",
    "    fine_tune_lr=0.0001,  # Learning rate for fine-tuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the adapted model\n",
    "torch.save(adapted_model.state_dict(), \"../models/base/mobilenet_v2_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f13621",
   "metadata": {},
   "source": [
    "### Audio Processing Model\n",
    "* Task: Audio classification\n",
    "* Model: YAMNet\n",
    "* Dataset: ESC-50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
