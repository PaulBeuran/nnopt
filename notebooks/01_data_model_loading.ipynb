{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b634e",
   "metadata": {},
   "source": [
    "# 1. Data & Model Loading\n",
    "\n",
    "This notebook prepares the data and models used for the subsequent optimisation pipeline. This is to emulate a non-compressed model training and evaluation process, where the model is adapted to a specific dataset and then exported for further compression for embedded deployment.\n",
    "\n",
    "The process is defined as such:\n",
    "* A Torch dataset (already split into train and val) and model are loaded. Those must be specialized for classification tasks, but are agnostic\n",
    "of the modality.\n",
    "* The model\"s classification head is adapted to the number of classes in the dataset, trained on the training set while freezing the backbone, and evaluated on the validation set.\n",
    "* The whole model (backbone + classification head) is then adapted to the dataset by freezing all layers except the classification head, which is trained on the training set.\n",
    "* The adapted model is then exported as a Torch model for later use in the optimisation pipeline.\n",
    "\n",
    "An image MobileNetV2 model with a classification head adapted to the CIFAR-10 dataset is used as an example in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571044d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effcbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbeuran/repos/nnopt/.venv/lib/python3.12/site-packages/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n",
      "2025-06-13 19:34:56,808 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Using device: cuda, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnopt.model.train import adapt_model_head_to_dataset\n",
    "from nnopt.model.eval import eval_model\n",
    "from nnopt.model.const import DEVICE, DTYPE, AMP_ENABLE\n",
    "from nnopt.recipes.mobilenetv2_cifar10 import init_mobilenetv2_cifar10_model, get_cifar10_datasets, save_mobilenetv2_cifar10_model, load_mobilenetv2_cifar10_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a00783",
   "metadata": {},
   "source": [
    "# MobileNetV2 and CIFAR-10 adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75facaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 19:34:56,816 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading MobileNetV2 model with weights: MobileNet_V2_Weights.IMAGENET1K_V1, to_quantize: False, is_quantized: False\n",
      "2025-06-13 19:34:56,896 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Replacing head of the model to match 10 classes\n",
      "2025-06-13 19:34:56,898 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading existing training and validation datasets...\n",
      "2025-06-13 19:34:58,540 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading existing test dataset...\n",
      "2025-06-13 19:34:58,870 - nnopt.model.train - INFO - Training head of the model with backbone frozen...\n",
      "Epoch 1/5 [Training]: 100%|██████████| 704/704 [00:38<00:00, 18.28it/s, acc=0.4921, cpu=3.5%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=38.0%, loss=1.7111, ram=10.7/30.9GB (45.5%), samples/s=334.4]  \n",
      "Epoch 1/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 38.82it/s, acc=0.6574, cpu=3.1%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=43.0%, loss=1.0329, ram=10.6/30.9GB (45.2%), samples/s=1087.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.4514, Train Acc: 0.4921, Train Throughput: 4289.79 samples/s | Val Loss: 0.9768, Val Acc: 0.6574, Val Throughput: 7879.72 samples/s | CPU Usage: 11.50% | RAM Usage: 10.5/30.9GB (44.6%) | GPU 0 Util: 43.00% | GPU 0 Mem: 15.8/24.0GB (65.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 704/704 [00:37<00:00, 18.60it/s, acc=0.5272, cpu=5.4%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=38.0%, loss=0.9983, ram=10.6/30.9GB (45.1%), samples/s=902.0]  \n",
      "Epoch 2/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.44it/s, acc=0.6588, cpu=3.3%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=41.0%, loss=1.0219, ram=10.6/30.9GB (45.1%), samples/s=1260.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 1.3412, Train Acc: 0.5272, Train Throughput: 4523.97 samples/s | Val Loss: 0.9767, Val Acc: 0.6588, Val Throughput: 7913.98 samples/s | CPU Usage: 12.30% | RAM Usage: 10.4/30.9GB (44.3%) | GPU 0 Util: 41.00% | GPU 0 Mem: 15.8/24.0GB (65.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 704/704 [00:37<00:00, 18.56it/s, acc=0.5402, cpu=5.9%, gpu_mem=15.8/24.0GB (66.0%), gpu_util=38.0%, loss=1.5239, ram=10.6/30.9GB (45.1%), samples/s=996.3]  \n",
      "Epoch 3/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 38.05it/s, acc=0.6438, cpu=3.4%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=42.0%, loss=0.8809, ram=10.6/30.9GB (44.9%), samples/s=1326.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 1.3097, Train Acc: 0.5402, Train Throughput: 4513.79 samples/s | Val Loss: 0.9929, Val Acc: 0.6438, Val Throughput: 7952.44 samples/s | CPU Usage: 12.20% | RAM Usage: 10.4/30.9GB (44.3%) | GPU 0 Util: 42.00% | GPU 0 Mem: 15.8/24.0GB (65.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 704/704 [00:37<00:00, 18.66it/s, acc=0.5320, cpu=2.8%, gpu_mem=15.8/24.0GB (65.8%), gpu_util=37.0%, loss=1.6794, ram=10.6/30.9GB (45.0%), samples/s=978.3]  \n",
      "Epoch 4/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.99it/s, acc=0.6446, cpu=0.0%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=45.0%, loss=0.9276, ram=10.6/30.9GB (45.2%), samples/s=1307.0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 1.3229, Train Acc: 0.5320, Train Throughput: 4558.82 samples/s | Val Loss: 0.9973, Val Acc: 0.6446, Val Throughput: 7753.33 samples/s | CPU Usage: 10.80% | RAM Usage: 10.4/30.9GB (44.4%) | GPU 0 Util: 45.00% | GPU 0 Mem: 15.8/24.0GB (65.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 704/704 [00:38<00:00, 18.52it/s, acc=0.5373, cpu=2.9%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=38.0%, loss=1.0306, ram=10.6/30.9GB (45.1%), samples/s=1010.7] \n",
      "Epoch 5/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.62it/s, acc=0.6692, cpu=3.3%, gpu_mem=15.8/24.0GB (65.9%), gpu_util=43.0%, loss=1.0234, ram=10.6/30.9GB (45.1%), samples/s=1263.8] \n",
      "2025-06-13 19:38:19,373 - nnopt.model.train - INFO - Fine-tuning full model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.3168, Train Acc: 0.5373, Train Throughput: 4530.86 samples/s | Val Loss: 0.9299, Val Acc: 0.6692, Val Throughput: 8109.89 samples/s | CPU Usage: 11.60% | RAM Usage: 10.4/30.9GB (44.3%) | GPU 0 Util: 43.00% | GPU 0 Mem: 15.8/24.0GB (65.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Training]: 100%|██████████| 704/704 [00:38<00:00, 18.30it/s, acc=0.6814, cpu=2.9%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=68.0%, loss=1.3158, ram=10.7/30.9GB (45.3%), samples/s=158.5]  \n",
      "Epoch 1/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.01it/s, acc=0.8770, cpu=3.2%, gpu_mem=18.3/24.0GB (76.2%), gpu_util=44.0%, loss=1.2640, ram=10.6/30.9GB (45.2%), samples/s=1242.0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.9096, Train Acc: 0.6814, Train Throughput: 1752.73 samples/s | Val Loss: 0.3518, Val Acc: 0.8770, Val Throughput: 7622.02 samples/s | CPU Usage: 12.00% | RAM Usage: 10.4/30.9GB (44.5%) | GPU 0 Util: 44.00% | GPU 0 Mem: 18.3/24.0GB (76.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 704/704 [00:39<00:00, 18.03it/s, acc=0.7593, cpu=4.5%, gpu_mem=18.3/24.0GB (76.2%), gpu_util=68.0%, loss=0.6965, ram=10.7/30.9GB (45.5%), samples/s=442.2]  \n",
      "Epoch 2/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.58it/s, acc=0.9104, cpu=3.6%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=45.0%, loss=0.7170, ram=10.7/30.9GB (45.5%), samples/s=1256.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.6937, Train Acc: 0.7593, Train Throughput: 1761.98 samples/s | Val Loss: 0.2676, Val Acc: 0.9104, Val Throughput: 7700.08 samples/s | CPU Usage: 11.50% | RAM Usage: 10.5/30.9GB (44.6%) | GPU 0 Util: 45.00% | GPU 0 Mem: 18.3/24.0GB (76.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 704/704 [00:39<00:00, 18.03it/s, acc=0.7834, cpu=1.5%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=67.0%, loss=0.5607, ram=10.7/30.9GB (45.5%), samples/s=428.8]  \n",
      "Epoch 3/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.42it/s, acc=0.9028, cpu=3.3%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=45.0%, loss=0.4503, ram=10.7/30.9GB (45.5%), samples/s=1232.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.6211, Train Acc: 0.7834, Train Throughput: 1757.00 samples/s | Val Loss: 0.2856, Val Acc: 0.9028, Val Throughput: 8108.88 samples/s | CPU Usage: 11.90% | RAM Usage: 10.5/30.9GB (44.6%) | GPU 0 Util: 45.00% | GPU 0 Mem: 18.3/24.0GB (76.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 704/704 [00:38<00:00, 18.08it/s, acc=0.8005, cpu=2.9%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=61.0%, loss=0.5784, ram=10.7/30.9GB (45.5%), samples/s=448.9]  \n",
      "Epoch 4/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.23it/s, acc=0.9202, cpu=0.0%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=46.0%, loss=0.6335, ram=10.7/30.9GB (45.5%), samples/s=1301.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.5777, Train Acc: 0.8005, Train Throughput: 1760.24 samples/s | Val Loss: 0.2292, Val Acc: 0.9202, Val Throughput: 7791.42 samples/s | CPU Usage: 12.30% | RAM Usage: 10.5/30.9GB (44.6%) | GPU 0 Util: 46.00% | GPU 0 Mem: 18.3/24.0GB (76.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 704/704 [00:38<00:00, 18.12it/s, acc=0.8087, cpu=3.1%, gpu_mem=18.3/24.0GB (76.2%), gpu_util=68.0%, loss=0.4400, ram=10.8/30.9GB (45.6%), samples/s=460.9]  \n",
      "Epoch 5/5 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 37.42it/s, acc=0.9242, cpu=0.0%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=40.0%, loss=1.0600, ram=10.7/30.9GB (45.5%), samples/s=1277.9] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.5493, Train Acc: 0.8087, Train Throughput: 1767.28 samples/s | Val Loss: 0.2148, Val Acc: 0.9242, Val Throughput: 8054.70 samples/s | CPU Usage: 11.50% | RAM Usage: 10.5/30.9GB (44.7%) | GPU 0 Util: 40.00% | GPU 0 Mem: 18.3/24.0GB (76.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2 = init_mobilenetv2_cifar10_model()\n",
    "cifar10_train_dataset, cifar10_val_dataset, cifar10_test_dataset = get_cifar10_datasets()\n",
    "\n",
    "# Adapt the MobileNetV2 model to CIFAR-10 dataset\n",
    "mobilenetv2_cifar10_baseline = adapt_model_head_to_dataset(\n",
    "    model=mobilenetv2,\n",
    "    train_dataset=cifar10_train_dataset,\n",
    "    val_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    head_train_epochs=5,  # Train head for fewer epochs\n",
    "    fine_tune_epochs=5,  # Fine-tune for fewer epochs\n",
    "    optimizer_cls=torch.optim.Adam,  # Use Adam optimizer\n",
    "    head_train_lr=0.001,  # Learning rate for head training\n",
    "    fine_tune_lr=0.0001,  # Learning rate for fine-tuning\n",
    "    use_amp=AMP_ENABLE,  # Use mixed precision training for efficiency\n",
    "    device=DEVICE, # Should be CUDA is available or CPU\n",
    "    dtype=DTYPE # Should be torch.float32 or torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb0b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 19:41:44,351 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.bfloat16, batch size: 64\n",
      "2025-06-13 19:41:44,354 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 12.49it/s]\n",
      "2025-06-13 19:41:44,852 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 79/79 [00:02<00:00, 37.33it/s, acc=0.9242, cpu=9.4%, gpu_mem=18.3/24.0GB (76.3%), gpu_util=45.0%, loss=1.0600, ram=10.8/30.9GB (45.5%), samples/s=1221.4] \n",
      "2025-06-13 19:41:46,974 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.bfloat16, batch size: 64\n",
      "2025-06-13 19:41:46,977 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2148, Accuracy: 0.9242\n",
      "Throughput: 7911.22 samples/sec | Avg Batch Time: 8.00 ms | Avg Sample Time: 0.13 ms\n",
      "System Stats: CPU Usage: 14.50% | RAM Usage: 10.5/30.9GB (44.7%) | GPU 0 Util: 45.00% | GPU 0 Mem: 18.3/24.0GB (76.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 14.79it/s]\n",
      "2025-06-13 19:41:47,412 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:04<00:00, 38.45it/s, acc=0.9273, cpu=3.2%, gpu_mem=18.3/24.0GB (76.2%), gpu_util=42.0%, loss=0.1041, ram=10.7/30.9GB (45.6%), samples/s=614.1]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2088, Accuracy: 0.9273\n",
      "Throughput: 7854.46 samples/sec | Avg Batch Time: 8.11 ms | Avg Sample Time: 0.13 ms\n",
      "System Stats: CPU Usage: 11.00% | RAM Usage: 10.5/30.9GB (44.7%) | GPU 0 Util: 42.00% | GPU 0 Mem: 18.3/24.0GB (76.2%)\n",
      "Validation accuracy of the adapted MobileNetV2 on CIFAR-10: 0.92\n",
      "Test accuracy of the adapted MobileNetV2 on CIFAR-10: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=AMP_ENABLE,\n",
    "    dtype=DTYPE\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=AMP_ENABLE,\n",
    "    dtype=DTYPE\n",
    ")\n",
    "print(f\"Validation accuracy of the adapted MobileNetV2 on CIFAR-10: {val_metrics['accuracy']:.2f}\")\n",
    "print(f\"Test accuracy of the adapted MobileNetV2 on CIFAR-10: {test_metrics['accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8406be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 19:41:51,561 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/model.pt\n",
      "2025-06-13 19:41:51,601 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Model state_dict saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/state_dict.pt\n",
      "2025-06-13 19:41:51,602 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Metadata saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/metadata.json\n",
      "2025-06-13 19:41:51,603 - nnopt.model.prune - INFO - Making pruning permanent by removing reparameterization...\n",
      "2025-06-13 19:41:51,603 - nnopt.model.prune - WARNING - No pruning reparameterization was removed. Was the model pruned?\n",
      "2025-06-13 19:41:51,603 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Saving model in JIT script format...\n",
      "2025-06-13 19:41:51,929 - nnopt.recipes.mobilenetv2_cifar10 - INFO - JIT script model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/jit_script.pt\n",
      "2025-06-13 19:41:51,930 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Saving model in JIT trace format...\n",
      "2025-06-13 19:41:52,612 - nnopt.recipes.mobilenetv2_cifar10 - INFO - JIT model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/jit_trace.pt\n"
     ]
    }
   ],
   "source": [
    "# Export the adapted model\n",
    "save_mobilenetv2_cifar10_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    metrics_values={\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "    },\n",
    "    version=\"mobilenetv2_cifar10/fp32/baseline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471158d",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f1b30",
   "metadata": {},
   "source": [
    "## GPU FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157d5d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 19:41:52,621 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.float32, batch size: 64\n",
      "2025-06-13 19:41:52,646 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00,  9.73it/s]\n",
      "2025-06-13 19:41:53,258 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 79/79 [00:02<00:00, 37.77it/s, acc=0.9244, cpu=7.2%, gpu_mem=18.9/24.0GB (78.7%), gpu_util=61.0%, loss=1.0547, ram=10.9/30.9GB (46.0%), samples/s=432.3]  \n",
      "2025-06-13 19:41:55,355 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.float32, batch size: 64\n",
      "2025-06-13 19:41:55,358 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2183, Accuracy: 0.9244\n",
      "Throughput: 5278.00 samples/sec | Avg Batch Time: 11.99 ms | Avg Sample Time: 0.19 ms\n",
      "System Stats: CPU Usage: 15.30% | RAM Usage: 10.7/30.9GB (45.4%) | GPU 0 Util: 61.00% | GPU 0 Mem: 18.9/24.0GB (78.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 12.47it/s]\n",
      "2025-06-13 19:41:55,871 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:03<00:00, 40.25it/s, acc=0.9267, cpu=1.6%, gpu_mem=18.8/24.0GB (78.5%), gpu_util=62.0%, loss=0.0984, ram=10.9/30.9GB (46.0%), samples/s=958.4]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2120, Accuracy: 0.9267\n",
      "Throughput: 5288.75 samples/sec | Avg Batch Time: 12.04 ms | Avg Sample Time: 0.19 ms\n",
      "System Stats: CPU Usage: 11.40% | RAM Usage: 10.7/30.9GB (45.4%) | GPU 0 Util: 62.00% | GPU 0 Mem: 18.8/24.0GB (78.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set on GPU\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=\"cuda\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=\"cuda\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4bdf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Validation Metrics:\n",
      "accuracy: 0.9244\n",
      "avg_loss: 0.21826240797042848\n",
      "avg_time_per_batch: 11.991510962086723\n",
      "avg_time_per_sample: 0.18946587320097025\n",
      "params_stats:\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 5277.995361936659\n",
      "\n",
      "- Test Metrics:\n",
      "accuracy: 0.9267\n",
      "avg_loss: 0.21195748742818832\n",
      "avg_time_per_batch: 12.043359070008059\n",
      "avg_time_per_sample: 0.1890807373991265\n",
      "params_stats:\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 5288.746033865529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the val metrics\n",
    "import yaml\n",
    "print(\"- Validation Metrics:\")\n",
    "yaml_str = yaml.dump(val_metrics, default_flow_style=False)\n",
    "print(yaml_str)\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"- Test Metrics:\")\n",
    "yaml_str = yaml.dump(test_metrics, default_flow_style=False)\n",
    "print(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1417d7",
   "metadata": {},
   "source": [
    "## CPU FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959f1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 19:41:59,818 - nnopt.model.eval - INFO - Starting evaluation on device: cpu, dtype: torch.float32, batch size: 32\n",
      "2025-06-13 19:41:59,857 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\n",
      "2025-06-13 19:42:02,472 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [01:07<00:00,  2.32it/s, acc=0.9242, cpu=43.6%, loss=1.0552, ram=11.0/30.9GB (47.6%), samples/s=138.8]\n",
      "2025-06-13 19:43:10,132 - nnopt.model.eval - INFO - Starting evaluation on device: cpu, dtype: torch.float32, batch size: 32\n",
      "2025-06-13 19:43:10,136 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2183, Accuracy: 0.9242\n",
      "Throughput: 74.58 samples/sec | Avg Batch Time: 426.99 ms | Avg Sample Time: 13.41 ms\n",
      "System Stats: CPU Usage: 14.20% | RAM Usage: 10.8/30.9GB (46.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n",
      "2025-06-13 19:43:12,743 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 313/313 [02:28<00:00,  2.11it/s, acc=0.9266, cpu=33.4%, loss=0.0986, ram=11.0/30.9GB (47.4%), samples/s=81.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2120, Accuracy: 0.9266\n",
      "Throughput: 67.69 samples/sec | Avg Batch Time: 471.98 ms | Avg Sample Time: 14.77 ms\n",
      "System Stats: CPU Usage: 12.80% | RAM Usage: 10.8/30.9GB (46.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set on CPU\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    device=\"cpu\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    device=\"cpu\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80077c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Validation Metrics:\n",
      "accuracy: 0.9242\n",
      "avg_loss: 0.21828886901140213\n",
      "avg_time_per_batch: 426.994085019183\n",
      "avg_time_per_sample: 13.407614269602345\n",
      "params_stats:\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 74.58448459896354\n",
      "\n",
      "- Test Metrics:\n",
      "accuracy: 0.9266\n",
      "avg_loss: 0.2119856424972415\n",
      "avg_time_per_batch: 471.9812060444592\n",
      "avg_time_per_sample: 14.773011749191573\n",
      "params_stats:\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 67.69100417555163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the val metrics\n",
    "import yaml\n",
    "print(\"- Validation Metrics:\")\n",
    "yaml_str = yaml.dump(val_metrics, default_flow_style=False)\n",
    "print(yaml_str)\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"- Test Metrics:\")\n",
    "yaml_str = yaml.dump(test_metrics, default_flow_style=False)\n",
    "print(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f638e",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* Accuracy is ~92.8% for CIFAR-10 with MobileNetV2, with fast convergence for so few epochs.\n",
    "* GPU is ~75 time faster than CPU for both training and evaluation, which is to be expected considering architecture differences.\n",
    "* Thus, if wanting to run the model on a CPU for embedded cases, and expect high throughput during inference with little-to-no accuracy loss, the model should be optimised for the CPU. This can be done with pruning, quantization, knowledge distillation.\n",
    "* Pruning and quantization are good candidates and explored in the next notebooks, while knowledge distillation isn't because of the already efficient architecture of MobileNetV2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
