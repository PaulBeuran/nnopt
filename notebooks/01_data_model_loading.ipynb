{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b634e",
   "metadata": {},
   "source": [
    "# 1. Data & Model Loading\n",
    "\n",
    "This notebook prepares the data and models used for the subsequent optimisation pipeline. This is to emulate a non-compressed model training and evaluation process, where the model is adapted to a specific dataset and then exported for further compression for embedded deployment.\n",
    "\n",
    "The process is defined as such:\n",
    "* A Torch dataset (already split into train and val) and model are loaded. Those must be specialized for classification tasks, but are agnostic\n",
    "of the modality.\n",
    "* The model\"s classification head is adapted to the number of classes in the dataset, trained on the training set while freezing the backbone, and evaluated on the validation set.\n",
    "* The whole model (backbone + classification head) is then adapted to the dataset by freezing all layers except the classification head, which is trained on the training set.\n",
    "* The adapted model is then exported as a Torch model for later use in the optimisation pipeline.\n",
    "\n",
    "2 models are exported:\n",
    "* An image MobileNetV2 model with a classification head adapted to the CIFAR-10 dataset.\n",
    "* An audio YAML model with a classification head adapted to the ESC-50 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571044d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084b2aa",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Literal\n",
    "from itertools import islice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.optim import Optimizer\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    pynvml_available = True\n",
    "except (ImportError, pynvml.NVMLError):\n",
    "    pynvml_available = False\n",
    "print(f\"pynvml available: {pynvml_available}\")\n",
    "\n",
    "# Setup device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "DTYPE = torch.bfloat16 if DEVICE == \"cuda\" else torch.float32\n",
    "\n",
    "# Base directories for datasets and models\n",
    "BASE_DATA_DIR = \"../data\"\n",
    "IMAGE_DATA_DIR = os.path.join(BASE_DATA_DIR, \"image\")\n",
    "BASE_MODEL_DIR = \"../models\"\n",
    "MODEL_BASELINE_DIR = os.path.join(BASE_MODEL_DIR, \"baseline\")\n",
    "\n",
    "# CIFAR-10 dataset directories\n",
    "CIFAR10_DIR = os.path.join(IMAGE_DATA_DIR, \"cifar10\")\n",
    "CIFAR10_TRAIN_DIR = os.path.join(CIFAR10_DIR, \"train\")\n",
    "CIFAR10_TRAIN_PT_FILE = os.path.join(CIFAR10_TRAIN_DIR, \"data.pt\")\n",
    "CIFAR10_VAL_DIR = os.path.join(CIFAR10_DIR, \"val\")\n",
    "CIFAR10_VAL_PT_FILE = os.path.join(CIFAR10_VAL_DIR, \"data.pt\")\n",
    "CIFAR10_TEST_DIR = os.path.join(CIFAR10_DIR, \"test\")\n",
    "CIFAR10_TEST_PT_FILE = os.path.join(CIFAR10_TEST_DIR, \"data.pt\")\n",
    "\n",
    "# MobileNetV2 model directory\n",
    "MOBILENETV2_CIFAR10_BASELINE_PT_FILE = os.path.join(MODEL_BASELINE_DIR, \"mobilenetv2_cifar10.pt\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d06ac",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08106169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_system_stats_msg(device: str) -> str:\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "    \n",
    "    vm = psutil.virtual_memory()\n",
    "    ram_used_gb = vm.used / (1024**3)\n",
    "    ram_total_gb = vm.total / (1024**3)\n",
    "    ram_msg = f\"{ram_used_gb:.1f}/{ram_total_gb:.1f}GB ({vm.percent:.1f}%)\"\n",
    "    \n",
    "    stats_msg = f\"CPU Usage: {cpu_usage:.2f}% | RAM Usage: {ram_msg}\"\n",
    "\n",
    "    if device == \"cuda\" and pynvml_available and torch.cuda.is_available():\n",
    "        try:\n",
    "            gpu_id = torch.cuda.current_device()\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)\n",
    "            gpu_util = pynvml.nvmlDeviceGetUtilizationRates(handle).gpu\n",
    "            \n",
    "            mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            vram_used_gb = mem_info.used / (1024**3)\n",
    "            vram_total_gb = mem_info.total / (1024**3)\n",
    "            gpu_mem_percent = mem_info.used / mem_info.total * 100\n",
    "            vram_msg = f\"{vram_used_gb:.1f}/{vram_total_gb:.1f}GB ({gpu_mem_percent:.1f}%)\"\n",
    "            \n",
    "            stats_msg += f\" | GPU {gpu_id} Util: {gpu_util:.2f}% | GPU {gpu_id} Mem: {vram_msg}\"\n",
    "        except pynvml.NVMLError as e:\n",
    "            stats_msg += f\" | GPU Stats Error: {e}\"\n",
    "    return stats_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de771fc",
   "metadata": {},
   "source": [
    "### Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2072b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run one pass (train, validation, or evaluation)\n",
    "def _run_one_pass(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    criterion: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    device: str,\n",
    "    use_amp: bool,\n",
    "    dtype: torch.dtype,\n",
    "    is_train_pass: bool,\n",
    "    optimizer: Optimizer | None = None,\n",
    "    scaler: GradScaler | None = None,\n",
    "    desc: str = \"Processing\",\n",
    "    enable_timing: bool = False\n",
    ") -> dict[str, float]:\n",
    "    if is_train_pass:\n",
    "        model.train()\n",
    "        if optimizer is None:\n",
    "            raise ValueError(\"Optimizer must be provided for training pass.\")\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_samples_processed = 0\n",
    "    \n",
    "    batch_times = []\n",
    "    \n",
    "    gpu_handle = None\n",
    "    if device == \"cuda\" and pynvml_available:\n",
    "        try:\n",
    "            gpu_id = torch.cuda.current_device()\n",
    "            gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)\n",
    "        except pynvml.NVMLError as e:\n",
    "            logger.warning(f\"Could not get GPU handle: {e}\")\n",
    "            gpu_handle = None\n",
    "\n",
    "    pbar = tqdm(loader, desc=desc)\n",
    "    \n",
    "    context_manager = torch.no_grad() if not is_train_pass else torch.enable_grad()\n",
    "    with context_manager:\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            batch_start_time = 0.0 \n",
    "            if enable_timing:\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                batch_start_time = time.perf_counter()\n",
    "\n",
    "            if is_train_pass and optimizer:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type=device, enabled=(use_amp and device == \"cuda\"), dtype=dtype if device == \"cuda\" else None):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            if is_train_pass and optimizer: \n",
    "                if scaler and use_amp and device == \"cuda\":\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            current_batch_duration = 0.0\n",
    "            if enable_timing:\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                batch_end_time = time.perf_counter()\n",
    "                current_batch_duration = batch_end_time - batch_start_time\n",
    "                batch_times.append(current_batch_duration)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0) \n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_preds += predicted.eq(labels).sum().item()\n",
    "            total_samples_processed += labels.size(0)\n",
    "\n",
    "            # --- Live stats for tqdm postfix ---\n",
    "            postfix_stats = {\"loss\": f\"{loss.item():.4f}\"}\n",
    "            if not is_train_pass: \n",
    "                current_acc = correct_preds / total_samples_processed if total_samples_processed > 0 else 0\n",
    "                postfix_stats[\"acc\"] = f\"{current_acc:.4f}\"\n",
    "\n",
    "            if enable_timing and current_batch_duration > 0:\n",
    "                samples_this_batch = inputs.size(0)\n",
    "                batch_throughput = samples_this_batch / current_batch_duration\n",
    "                postfix_stats[\"samples/s\"] = f\"{batch_throughput:.1f}\" # samples per second\n",
    "            \n",
    "            # System stats\n",
    "            postfix_stats[\"cpu\"] = f\"{psutil.cpu_percent():.1f}%\"\n",
    "            \n",
    "            vm = psutil.virtual_memory()\n",
    "            ram_used_gb = vm.used / (1024**3)\n",
    "            ram_total_gb = vm.total / (1024**3)\n",
    "            postfix_stats[\"ram\"] = f\"{ram_used_gb:.1f}/{ram_total_gb:.1f}GB ({vm.percent:.1f}%)\"\n",
    "\n",
    "            if device == \"cuda\" and pynvml_available and gpu_handle:\n",
    "                try:\n",
    "                    gpu_util = pynvml.nvmlDeviceGetUtilizationRates(gpu_handle).gpu\n",
    "                    mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "                    vram_used_gb = mem_info.used / (1024**3)\n",
    "                    vram_total_gb = mem_info.total / (1024**3)\n",
    "                    gpu_mem_percent = mem_info.used / mem_info.total * 100\n",
    "                    postfix_stats[\"gpu_util\"] = f\"{gpu_util:.1f}%\"\n",
    "                    postfix_stats[\"gpu_mem\"] = f\"{vram_used_gb:.1f}/{vram_total_gb:.1f}GB ({gpu_mem_percent:.1f}%)\"\n",
    "                except pynvml.NVMLError:\n",
    "                    postfix_stats[\"gpu_util\"] = \"N/A\"\n",
    "                    postfix_stats[\"gpu_mem\"] = \"N/A\"\n",
    "            \n",
    "            pbar.set_postfix(**postfix_stats)\n",
    "            # --- End live stats ---\n",
    "\n",
    "    avg_loss = total_loss / total_samples_processed if total_samples_processed > 0 else 0\n",
    "    accuracy = correct_preds / total_samples_processed if total_samples_processed > 0 else 0\n",
    "    \n",
    "    results = {\"avg_loss\": avg_loss, \"accuracy\": accuracy, \"total_samples_processed\": float(total_samples_processed)}\n",
    "    \n",
    "    if enable_timing and batch_times: \n",
    "        total_inference_time = sum(batch_times)\n",
    "        num_timed_batches = len(batch_times)\n",
    "        results[\"total_inference_time\"] = total_inference_time\n",
    "        results[\"num_timed_batches\"] = float(num_timed_batches)\n",
    "        \n",
    "        results[\"avg_time_per_batch\"] = total_inference_time / num_timed_batches if num_timed_batches > 0 else 0\n",
    "        results[\"avg_time_per_sample\"] = total_inference_time / total_samples_processed if total_samples_processed > 0 else 0\n",
    "        results[\"samples_per_second\"] = total_samples_processed / total_inference_time if total_inference_time > 0 else 0\n",
    "    else: \n",
    "        results[\"total_inference_time\"] = 0.0\n",
    "        results[\"num_timed_batches\"] = 0.0\n",
    "        results[\"avg_time_per_batch\"] = 0.0\n",
    "        results[\"avg_time_per_sample\"] = 0.0\n",
    "        results[\"samples_per_second\"] = 0.0\n",
    "\n",
    "    return results\n",
    "\n",
    "# Training loop function\n",
    "def train_loop(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    epochs: int,\n",
    "    criterion: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    optimizer: Optimizer,\n",
    "    device: Literal[\"cpu\", \"cuda\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_amp: bool = True, \n",
    "    dtype: torch.dtype = torch.bfloat16 \n",
    "):\n",
    "    model.to(device)\n",
    "    \n",
    "    scaler = GradScaler(enabled=(use_amp and device == \"cuda\")) \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train step\n",
    "        train_results = _run_one_pass(\n",
    "            model=model,\n",
    "            loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            use_amp=use_amp,\n",
    "            dtype=dtype,\n",
    "            is_train_pass=True,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            desc=f\"Epoch {epoch+1}/{epochs} [Training]\",\n",
    "            enable_timing=True\n",
    "        )\n",
    "        \n",
    "        # Validation step\n",
    "        val_results = _run_one_pass(\n",
    "            model=model,\n",
    "            loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            use_amp=use_amp,\n",
    "            dtype=dtype,\n",
    "            is_train_pass=False,\n",
    "            desc=f\"Epoch {epoch+1}/{epochs} [Validation]\",\n",
    "            enable_timing=True\n",
    "        )\n",
    "        \n",
    "        stats_msg = _get_system_stats_msg(device)\n",
    "        train_samples_per_second = train_results.get(\"samples_per_second\", 0.0)\n",
    "        train_accuracy = train_results.get(\"accuracy\", 0.0)\n",
    "        val_samples_per_second = val_results.get(\"samples_per_second\", 0.0)\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch+1}/{epochs}, \"\n",
    "            f\"Train Loss: {train_results['avg_loss']:.4f}, Train Acc: {train_accuracy:.4f}, Train Throughput: {train_samples_per_second:.2f} samples/s | \"\n",
    "            f\"Val Loss: {val_results['avg_loss']:.4f}, Val Acc: {val_results['accuracy']:.4f}, Val Throughput: {val_samples_per_second:.2f} samples/s | \"\n",
    "            f\"{stats_msg}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Function to adapt a classification model to a new dataset as such:\n",
    "# * Load the pretrained model from torchvision or torchaudio\n",
    "# * Replace the final layer to match the number of classes in the new dataset\n",
    "# * Train the head of the model with the backbone freezed on the new dataset\n",
    "# * After training the head, unfreeze the backbone and fine-tune the entire model\n",
    "# * Augment the dataset with random transformations\n",
    "def adapt_model_head_to_dataset(\n",
    "    model: torch.nn.Module, \n",
    "    num_classes: int, \n",
    "    train_dataset: torch.utils.data.Dataset, \n",
    "    val_dataset: torch.utils.data.Dataset,\n",
    "    batch_size: int = 32,\n",
    "    shuffle: bool = True,\n",
    "    num_workers: int = 4,\n",
    "    pin_memory: bool = True,\n",
    "    head_train_epochs: int = 10,\n",
    "    fine_tune_epochs: int = 5,\n",
    "    optimizer_cls: type[Optimizer] = torch.optim.Adam, # Changed to optimizer_cls\n",
    "    head_train_lr: float = 0.001,\n",
    "    fine_tune_lr: float = 0.0001,\n",
    "    device: Literal[\"cpu\", \"cuda\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_amp: bool = True,\n",
    "    dtype: torch.dtype = torch.bfloat16\n",
    ") -> torch.nn.Module:\n",
    "\n",
    "    # Replace the final layer\n",
    "    if hasattr(model, \"fc\"):\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif hasattr(model, \"classifier\") and isinstance(model.classifier, torch.nn.Sequential):\n",
    "        # Common case for models like MobileNetV2, EfficientNet\n",
    "        if hasattr(model.classifier[-1], \"in_features\"):\n",
    "            model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "        else:\n",
    "            # Fallback for other structures if needed, this might require specific handling\n",
    "            logger.warning(f\"Warning: Classifier final layer replacement might be inexact.\")\n",
    "            # Attempt to find the last linear layer if possible, or raise error\n",
    "            for i in range(len(model.classifier) -1, -1, -1):\n",
    "                if isinstance(model.classifier[i], torch.nn.Linear):\n",
    "                    model.classifier[i] = torch.nn.Linear(model.classifier[i].in_features, num_classes)\n",
    "                    break\n",
    "            else:\n",
    "                raise AttributeError(f\"Could not find a final Linear layer in classifier\")\n",
    "\n",
    "    elif hasattr(model, \"classifier\") and isinstance(model.classifier, torch.nn.Linear): # e.g. some ViT models\n",
    "        model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "    else:\n",
    "        raise AttributeError(f\"\"\"Model does not have \"fc\" or a known \"classifier\" structure to replace.\"\"\")\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=shuffle, \n",
    "                                               num_workers=num_workers, \n",
    "                                               pin_memory=pin_memory)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size, \n",
    "                                             shuffle=False, \n",
    "                                             num_workers=num_workers, \n",
    "                                             pin_memory=pin_memory)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Train the head ---\n",
    "    logger.info(\"Training head of the model with backbone frozen...\")\n",
    "    # Freeze the backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze the final layer (fc or classifier)\n",
    "    if hasattr(model, \"fc\"):\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        for param in model.classifier.parameters(): # Unfreeze all params in the classifier block\n",
    "            param.requires_grad = True\n",
    "    else: # Should not happen due to checks above\n",
    "        raise AttributeError(\"Final layer not found for unfreezing.\")\n",
    "\n",
    "    optimizer_head = optimizer_cls(filter(lambda p: p.requires_grad, model.parameters()), lr=head_train_lr)\n",
    "    \n",
    "    train_loop(model, train_loader, val_loader, head_train_epochs, criterion, optimizer_head, device, use_amp, dtype)\n",
    "\n",
    "    # --- Fine-tune the entire model ---\n",
    "    logger.info(\"Fine-tuning full model...\")\n",
    "    # Unfreeze the backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer_finetune = optimizer_cls(model.parameters(), lr=fine_tune_lr)\n",
    "\n",
    "    train_loop(model, train_loader, val_loader, fine_tune_epochs, criterion, optimizer_finetune, device, use_amp, dtype)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba918de",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99198a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate a model on a test dataset and return the mean accuracy\n",
    "def eval_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_dataset: torch.utils.data.Dataset, # test_dataset is used for total_samples_for_throughput if loader is partial\n",
    "    batch_size: int = 32,\n",
    "    criterion: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = torch.nn.CrossEntropyLoss(),\n",
    "    device: Literal[\"cpu\", \"cuda\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_amp: bool = True,\n",
    "    dtype: torch.dtype = torch.bfloat16,\n",
    "    num_warmup_batches: int = 5,\n",
    "    num_workers: int = 4, \n",
    "    pin_memory: bool = True \n",
    ") -> float:\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    # Warmup phase\n",
    "    if num_warmup_batches > 0 and len(test_loader) > num_warmup_batches : \n",
    "        logger.info(f\"Starting warmup for {num_warmup_batches} batches...\")\n",
    "        warmup_loader = islice(test_loader, num_warmup_batches)\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(warmup_loader, total=num_warmup_batches, desc=\"[Warmup]\"):\n",
    "                inputs = inputs.to(device)\n",
    "                with autocast(device_type=device, enabled=(use_amp and device == \"cuda\"), dtype=dtype if device == \"cuda\" else None):\n",
    "                    _ = model(inputs)\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        logger.info(\"Warmup complete.\")\n",
    "\n",
    "    # Main evaluation pass\n",
    "    eval_results = _run_one_pass(\n",
    "        model=model,\n",
    "        loader=test_loader, \n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        use_amp=use_amp,\n",
    "        dtype=dtype,\n",
    "        is_train_pass=False,\n",
    "        desc=\"[Evaluation]\",\n",
    "        enable_timing=True # Crucial: ensure timing is enabled\n",
    "    )\n",
    "\n",
    "    avg_eval_loss = eval_results[\"avg_loss\"]\n",
    "    eval_accuracy = eval_results[\"accuracy\"]\n",
    "    \n",
    "    # Retrieve throughput metrics directly from eval_results\n",
    "    samples_per_second = eval_results.get(\"samples_per_second\", 0)\n",
    "    avg_time_per_batch = eval_results.get(\"avg_time_per_batch\", 0)\n",
    "    avg_time_per_sample = eval_results.get(\"avg_time_per_sample\", 0)\n",
    "\n",
    "    throughput_msg = (f\"Throughput: {samples_per_second:.2f} samples/sec | \"\n",
    "                      f\"Avg Batch Time: {avg_time_per_batch*1000:.2f} ms | \"\n",
    "                      f\"Avg Sample Time: {avg_time_per_sample*1000:.2f} ms\")\n",
    "    \n",
    "    stats_msg = _get_system_stats_msg(device)\n",
    "    \n",
    "    tqdm.write(f\"Evaluation Complete: Avg Loss: {avg_eval_loss:.4f}, Accuracy: {eval_accuracy:.4f}\")\n",
    "    tqdm.write(throughput_msg)\n",
    "    tqdm.write(f\"System Stats: {stats_msg}\")\n",
    "    \n",
    "    return eval_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b62655",
   "metadata": {},
   "source": [
    "# Image Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000663ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 11:31:23,636 - __main__ - INFO - Loading existing training and validation datasets...\n",
      "2025-06-10 11:31:25,267 - __main__ - INFO - Loading existing test dataset...\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2 model\n",
    "mobilnet_v2 = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "# CIFAR-10 dataset transforms for MobileNetV2\n",
    "image_train_cifar10_mobilenetV2_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Use ImageNet means/stds\n",
    "])\n",
    "image_val_cifar10_mobilenetV2_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # Use ImageNet means/stds\n",
    "])\n",
    "\n",
    "# CIFAR-10 datasets\n",
    "if (not os.path.exists(CIFAR10_TEST_PT_FILE) or \n",
    "    not os.path.exists(CIFAR10_VAL_PT_FILE)):\n",
    "    logger.info(\"Training and/or validation dataset does not exist, creating, splitting and saving...\")\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=CIFAR10_TRAIN_DIR,\n",
    "        train=True,\n",
    "        transform=image_train_cifar10_mobilenetV2_transform,\n",
    "        download=True\n",
    "    )\n",
    "    train_val_split_generator = torch.Generator().manual_seed(42069)  # For reproducibility\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [45000, 5000], \n",
    "                                                            generator=train_val_split_generator)\n",
    "    torch.save(train_dataset, CIFAR10_TRAIN_PT_FILE)\n",
    "    torch.save(val_dataset, CIFAR10_VAL_PT_FILE)\n",
    "else:\n",
    "    logger.info(\"Loading existing training and validation datasets...\")\n",
    "    train_dataset = torch.load(CIFAR10_TRAIN_PT_FILE, weights_only=False)\n",
    "    val_dataset = torch.load(CIFAR10_VAL_PT_FILE, weights_only=False)\n",
    "if not os.path.exists(CIFAR10_TEST_PT_FILE):\n",
    "    logger.info(\"Test dataset does not exist, creating and saving...\")\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=CIFAR10_TEST_DIR,\n",
    "        train=False,\n",
    "        transform=image_val_cifar10_mobilenetV2_transform,\n",
    "        download=True\n",
    "    )\n",
    "    torch.save(test_dataset, CIFAR10_TEST_PT_FILE)\n",
    "else:\n",
    "    logger.info(\"Loading existing test dataset...\")\n",
    "    test_dataset = torch.load(CIFAR10_TEST_PT_FILE, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75facaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 11:31:26,662 - __main__ - INFO - Training head of the model with backbone frozen...\n",
      "Epoch 1/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.97it/s, cpu=4.8%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=35.0%, loss=0.8872, ram=6.0/30.9GB (22.8%), samples/s=360.9]  \n",
      "Epoch 1/5 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.48it/s, acc=0.5332, cpu=3.7%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=33.0%, loss=1.1550, ram=5.9/30.9GB (22.6%), samples/s=1300.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.5391, Train Acc: 0.4722, Train Throughput: 3829.16 samples/s | Val Loss: 1.3585, Val Acc: 0.5332, Val Throughput: 4957.31 samples/s | CPU Usage: 10.10% | RAM Usage: 5.7/30.9GB (21.9%) | GPU 0 Util: 33.00% | GPU 0 Mem: 3.3/24.0GB (13.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 704/704 [00:33<00:00, 20.83it/s, cpu=3.1%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=45.0%, loss=0.9769, ram=5.9/30.9GB (22.6%), samples/s=1043.3] \n",
      "Epoch 2/5 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.69it/s, acc=0.5356, cpu=0.0%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=38.0%, loss=1.5044, ram=5.9/30.9GB (22.6%), samples/s=1368.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 1.3754, Train Acc: 0.5198, Train Throughput: 4051.54 samples/s | Val Loss: 1.3059, Val Acc: 0.5356, Val Throughput: 5606.48 samples/s | CPU Usage: 12.90% | RAM Usage: 5.7/30.9GB (21.9%) | GPU 0 Util: 36.00% | GPU 0 Mem: 3.3/24.0GB (13.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 704/704 [00:34<00:00, 20.19it/s, cpu=11.4%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=46.0%, loss=1.6875, ram=5.9/30.9GB (22.7%), samples/s=1016.5]\n",
      "Epoch 3/5 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.82it/s, acc=0.5504, cpu=3.4%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=35.0%, loss=1.5875, ram=5.9/30.9GB (22.6%), samples/s=1342.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 1.3402, Train Acc: 0.5316, Train Throughput: 3916.17 samples/s | Val Loss: 1.2706, Val Acc: 0.5504, Val Throughput: 5125.20 samples/s | CPU Usage: 10.00% | RAM Usage: 5.7/30.9GB (22.0%) | GPU 0 Util: 26.00% | GPU 0 Mem: 3.3/24.0GB (13.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 704/704 [00:34<00:00, 20.22it/s, cpu=2.9%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=42.0%, loss=1.6812, ram=6.0/30.9GB (22.9%), samples/s=948.9]  \n",
      "Epoch 4/5 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.72it/s, acc=0.5504, cpu=7.1%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=37.0%, loss=1.6696, ram=5.9/30.9GB (22.7%), samples/s=1313.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 1.3324, Train Acc: 0.5344, Train Throughput: 3806.95 samples/s | Val Loss: 1.2721, Val Acc: 0.5504, Val Throughput: 4978.24 samples/s | CPU Usage: 9.70% | RAM Usage: 5.7/30.9GB (22.0%) | GPU 0 Util: 29.00% | GPU 0 Mem: 3.3/24.0GB (13.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 704/704 [00:34<00:00, 20.27it/s, cpu=6.1%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=37.0%, loss=0.7859, ram=5.9/30.9GB (22.6%), samples/s=1078.3] \n",
      "Epoch 5/5 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.91it/s, acc=0.5576, cpu=3.6%, gpu_mem=3.3/24.0GB (13.9%), gpu_util=36.0%, loss=1.7557, ram=6.0/30.9GB (22.8%), samples/s=1250.0] \n",
      "2025-06-10 11:34:41,294 - __main__ - INFO - Fine-tuning full model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.3202, Train Acc: 0.5364, Train Throughput: 3891.03 samples/s | Val Loss: 1.2601, Val Acc: 0.5576, Val Throughput: 4682.43 samples/s | CPU Usage: 11.00% | RAM Usage: 5.7/30.9GB (22.0%) | GPU 0 Util: 36.00% | GPU 0 Mem: 3.3/24.0GB (13.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.93it/s, cpu=3.1%, gpu_mem=5.9/24.0GB (24.5%), gpu_util=69.0%, loss=1.1902, ram=6.0/30.9GB (23.1%), samples/s=167.1]  \n",
      "Epoch 1/3 [Validation]: 100%|██████████| 79/79 [00:03<00:00, 22.86it/s, acc=0.7220, cpu=3.4%, gpu_mem=5.9/24.0GB (24.5%), gpu_util=31.0%, loss=1.0942, ram=6.0/30.9GB (22.9%), samples/s=1206.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 1.0154, Train Acc: 0.6437, Train Throughput: 1898.05 samples/s | Val Loss: 0.7955, Val Acc: 0.7220, Val Throughput: 6938.35 samples/s | CPU Usage: 11.10% | RAM Usage: 5.8/30.9GB (22.2%) | GPU 0 Util: 31.00% | GPU 0 Mem: 5.9/24.0GB (24.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Training]: 100%|██████████| 704/704 [00:35<00:00, 20.04it/s, cpu=3.2%, gpu_mem=5.8/24.0GB (24.2%), gpu_util=65.0%, loss=1.1772, ram=6.0/30.9GB (22.9%), samples/s=467.4]  \n",
      "Epoch 2/3 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.94it/s, acc=0.7524, cpu=3.4%, gpu_mem=5.8/24.0GB (24.2%), gpu_util=35.0%, loss=1.0018, ram=6.0/30.9GB (22.8%), samples/s=1208.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.7797, Train Acc: 0.7271, Train Throughput: 1902.91 samples/s | Val Loss: 0.7145, Val Acc: 0.7524, Val Throughput: 6454.56 samples/s | CPU Usage: 10.30% | RAM Usage: 5.8/30.9GB (22.2%) | GPU 0 Util: 35.00% | GPU 0 Mem: 5.8/24.0GB (24.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Training]: 100%|██████████| 704/704 [00:35<00:00, 20.03it/s, cpu=4.9%, gpu_mem=5.8/24.0GB (24.2%), gpu_util=68.0%, loss=0.7917, ram=6.0/30.9GB (22.9%), samples/s=483.0]  \n",
      "Epoch 3/3 [Validation]: 100%|██████████| 79/79 [00:04<00:00, 18.71it/s, acc=0.7780, cpu=6.3%, gpu_mem=5.8/24.0GB (24.2%), gpu_util=33.0%, loss=0.5619, ram=6.0/30.9GB (22.9%), samples/s=1136.7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.7031, Train Acc: 0.7539, Train Throughput: 1910.49 samples/s | Val Loss: 0.6464, Val Acc: 0.7780, Val Throughput: 6329.79 samples/s | CPU Usage: 10.10% | RAM Usage: 5.8/30.9GB (22.2%) | GPU 0 Util: 33.00% | GPU 0 Mem: 5.8/24.0GB (24.2%)\n"
     ]
    }
   ],
   "source": [
    "# Adapt the MobileNetV2 model to CIFAR-10 dataset\n",
    "adapted_model = adapt_model_head_to_dataset(\n",
    "    model=mobilnet_v2,\n",
    "    num_classes=10,  # CIFAR-10 has 10 classes\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    head_train_epochs=5,  # Train head for fewer epochs\n",
    "    fine_tune_epochs=3,  # Fine-tune for fewer epochs\n",
    "    optimizer_cls=torch.optim.Adam,  # Use Adam optimizer\n",
    "    head_train_lr=0.001,  # Learning rate for head training\n",
    "    fine_tune_lr=0.0001,  # Learning rate for fine-tuning\n",
    "    use_amp=True,  # Use mixed precision training\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb0b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 11:36:47,799 - __main__ - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00,  9.03it/s]\n",
      "2025-06-10 11:36:48,431 - __main__ - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:03<00:00, 52.01it/s, acc=0.9011, cpu=3.6%, gpu_mem=5.8/24.0GB (24.3%), gpu_util=39.0%, loss=0.0931, ram=6.1/30.9GB (23.5%), samples/s=681.8]  \n",
      "2025-06-10 11:36:51,454 - __main__ - INFO - Test accuracy of the adapted MobileNetV2 model on CIFAR-10: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2962, Accuracy: 0.9011\n",
      "Throughput: 8391.41 samples/sec | Avg Batch Time: 7.59 ms | Avg Sample Time: 0.12 ms\n",
      "System Stats: CPU Usage: 11.90% | RAM Usage: 5.9/30.9GB (22.8%) | GPU 0 Util: 39.00% | GPU 0 Mem: 5.8/24.0GB (24.3%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation set\n",
    "test_accuracy = eval_model(\n",
    "    model=adapted_model,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=True,\n",
    "    dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "logger.info(f\"Test accuracy of the adapted MobileNetV2 model on CIFAR-10: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the adapted model\n",
    "torch.save(adapted_model.state_dict(), MOBILENETV2_CIFAR10_BASELINE_PT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
