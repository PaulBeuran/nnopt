{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b634e",
   "metadata": {},
   "source": [
    "# 1. Data & Model Loading\n",
    "\n",
    "This notebook prepares the data and models used for the subsequent optimisation pipeline. This is to emulate a non-compressed model training and evaluation process, where the model is adapted to a specific dataset and then exported for further compression for embedded deployment.\n",
    "\n",
    "The process is defined as such:\n",
    "* A Torch dataset (already split into train and val) and model are loaded. Those must be specialized for classification tasks, but are agnostic\n",
    "of the modality.\n",
    "* The model\"s classification head is adapted to the number of classes in the dataset, trained on the training set while freezing the backbone, and evaluated on the validation set.\n",
    "* The whole model (backbone + classification head) is then adapted to the dataset by freezing all layers except the classification head, which is trained on the training set.\n",
    "* The adapted model is then exported as a Torch model for later use in the optimisation pipeline.\n",
    "\n",
    "An image MobileNetV2 model with a classification head adapted to the CIFAR-10 dataset is used as an example in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571044d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 10:37:56,802 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Using device: cuda, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnopt.model.train import adapt_model_head_to_dataset\n",
    "from nnopt.model.eval import eval_model\n",
    "from nnopt.model.const import DEVICE, DTYPE, AMP_ENABLE\n",
    "from nnopt.recipes.mobilenetv2_cifar10 import init_mobilenetv2_cifar10_model, get_cifar10_datasets, save_mobilenetv2_cifar10_model, load_mobilenetv2_cifar10_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a00783",
   "metadata": {},
   "source": [
    "# MobileNetV2 and CIFAR-10 adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75facaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 10:41:39,106 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading MobileNetV2 model with weights: MobileNet_V2_Weights.IMAGENET1K_V1, to_quantize: False, is_quantized: False, num_classes: 10\n",
      "2025-06-12 10:41:39,152 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Replacing head of the model to match 10 classes\n",
      "2025-06-12 10:41:39,154 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading existing training and validation datasets...\n",
      "2025-06-12 10:41:40,621 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading existing test dataset...\n",
      "2025-06-12 10:41:40,773 - nnopt.model.train - INFO - Training head of the model with backbone frozen...\n",
      "Epoch 1/5 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.54it/s, acc=0.4885, cpu=3.6%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=35.0%, loss=2.4434, ram=9.2/30.9GB (39.4%), samples/s=1202.4] \n",
      "Epoch 1/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 43.14it/s, acc=0.6566, cpu=0.0%, gpu_mem=15.5/24.0GB (64.6%), gpu_util=38.0%, loss=1.1313, ram=9.2/30.9GB (39.3%), samples/s=1544.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.4494, Train Acc: 0.4885, Train Throughput: 4263.55 samples/s | Val Loss: 0.9658, Val Acc: 0.6566, Val Throughput: 8564.91 samples/s | CPU Usage: 12.80% | RAM Usage: 9.0/30.9GB (38.4%) | GPU 0 Util: 38.00% | GPU 0 Mem: 15.5/24.0GB (64.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.69it/s, acc=0.5300, cpu=3.1%, gpu_mem=15.5/24.0GB (64.6%), gpu_util=40.0%, loss=1.0195, ram=9.3/30.9GB (39.6%), samples/s=1091.5] \n",
      "Epoch 2/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 43.29it/s, acc=0.6864, cpu=3.6%, gpu_mem=15.5/24.0GB (64.6%), gpu_util=38.0%, loss=1.2681, ram=9.3/30.9GB (39.6%), samples/s=1467.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 1.3353, Train Acc: 0.5300, Train Throughput: 4276.14 samples/s | Val Loss: 0.9010, Val Acc: 0.6864, Val Throughput: 9078.04 samples/s | CPU Usage: 9.80% | RAM Usage: 9.0/30.9GB (38.7%) | GPU 0 Util: 38.00% | GPU 0 Mem: 15.5/24.0GB (64.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.05it/s, acc=0.5332, cpu=3.1%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=37.0%, loss=1.4594, ram=9.3/30.9GB (39.5%), samples/s=1067.9] \n",
      "Epoch 3/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 43.38it/s, acc=0.6662, cpu=4.0%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=39.0%, loss=0.8524, ram=9.3/30.9GB (39.5%), samples/s=1478.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 1.3242, Train Acc: 0.5332, Train Throughput: 4206.87 samples/s | Val Loss: 0.9348, Val Acc: 0.6662, Val Throughput: 8850.24 samples/s | CPU Usage: 11.10% | RAM Usage: 9.0/30.9GB (38.7%) | GPU 0 Util: 39.00% | GPU 0 Mem: 15.5/24.0GB (64.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 704/704 [00:34<00:00, 20.22it/s, acc=0.5392, cpu=0.0%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=40.0%, loss=0.9433, ram=9.3/30.9GB (39.6%), samples/s=1081.9] \n",
      "Epoch 4/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 43.75it/s, acc=0.6518, cpu=3.4%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=38.0%, loss=1.0523, ram=9.3/30.9GB (39.5%), samples/s=1377.0]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 1.3208, Train Acc: 0.5392, Train Throughput: 4202.78 samples/s | Val Loss: 0.9768, Val Acc: 0.6518, Val Throughput: 8561.41 samples/s | CPU Usage: 14.30% | RAM Usage: 9.0/30.9GB (38.7%) | GPU 0 Util: 36.00% | GPU 0 Mem: 15.5/24.0GB (64.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 704/704 [00:37<00:00, 18.77it/s, acc=0.5388, cpu=6.5%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=39.0%, loss=1.6631, ram=9.3/30.9GB (39.5%), samples/s=1098.6] \n",
      "Epoch 5/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 42.92it/s, acc=0.6610, cpu=3.6%, gpu_mem=15.5/24.0GB (64.5%), gpu_util=40.0%, loss=1.0176, ram=9.3/30.9GB (39.5%), samples/s=1445.9]  \n",
      "2025-06-12 10:44:50,999 - nnopt.model.train - INFO - Fine-tuning full model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.3209, Train Acc: 0.5388, Train Throughput: 4012.76 samples/s | Val Loss: 0.9607, Val Acc: 0.6610, Val Throughput: 8514.76 samples/s | CPU Usage: 10.50% | RAM Usage: 9.0/30.9GB (38.6%) | GPU 0 Util: 40.00% | GPU 0 Mem: 15.5/24.0GB (64.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 20.07it/s, acc=0.6821, cpu=3.4%, gpu_mem=18.0/24.0GB (75.0%), gpu_util=62.0%, loss=2.2703, ram=9.4/30.9GB (39.8%), samples/s=182.3]  \n",
      "Epoch 1/5 [Validation]: 100%|██████████| 79/79 [00:05<00:00, 14.37it/s, acc=0.8854, cpu=0.0%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=38.0%, loss=0.4311, ram=9.4/30.9GB (39.8%), samples/s=1344.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.9125, Train Acc: 0.6821, Train Throughput: 2183.96 samples/s | Val Loss: 0.3333, Val Acc: 0.8854, Val Throughput: 8838.10 samples/s | CPU Usage: 12.90% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 31.00% | GPU 0 Mem: 18.0/24.0GB (75.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.49it/s, acc=0.7559, cpu=3.6%, gpu_mem=18.0/24.0GB (75.0%), gpu_util=63.0%, loss=0.7060, ram=9.4/30.9GB (39.8%), samples/s=529.9]  \n",
      "Epoch 2/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 43.34it/s, acc=0.8990, cpu=4.0%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=38.0%, loss=0.6878, ram=9.4/30.9GB (39.8%), samples/s=1478.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.7015, Train Acc: 0.7559, Train Throughput: 2141.56 samples/s | Val Loss: 0.2846, Val Acc: 0.8990, Val Throughput: 9535.81 samples/s | CPU Usage: 10.50% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 34.00% | GPU 0 Mem: 18.0/24.0GB (75.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.20it/s, acc=0.7775, cpu=3.6%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=64.0%, loss=0.6134, ram=9.4/30.9GB (39.8%), samples/s=526.6]  \n",
      "Epoch 3/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 42.63it/s, acc=0.9054, cpu=0.0%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=39.0%, loss=0.7339, ram=9.4/30.9GB (39.8%), samples/s=1445.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.6329, Train Acc: 0.7775, Train Throughput: 2161.97 samples/s | Val Loss: 0.2739, Val Acc: 0.9054, Val Throughput: 8860.93 samples/s | CPU Usage: 11.50% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 39.00% | GPU 0 Mem: 18.0/24.0GB (75.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.47it/s, acc=0.7975, cpu=7.0%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=66.0%, loss=0.4283, ram=9.4/30.9GB (39.8%), samples/s=524.3]  \n",
      "Epoch 4/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 43.25it/s, acc=0.9216, cpu=3.8%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=38.0%, loss=0.7340, ram=9.4/30.9GB (39.8%), samples/s=1454.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.5791, Train Acc: 0.7975, Train Throughput: 2178.57 samples/s | Val Loss: 0.2252, Val Acc: 0.9216, Val Throughput: 9675.00 samples/s | CPU Usage: 10.60% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 38.00% | GPU 0 Mem: 18.0/24.0GB (75.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.21it/s, acc=0.8078, cpu=3.4%, gpu_mem=18.0/24.0GB (75.0%), gpu_util=64.0%, loss=0.8391, ram=9.4/30.9GB (39.8%), samples/s=515.0]  \n",
      "Epoch 5/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 42.44it/s, acc=0.9254, cpu=7.4%, gpu_mem=18.0/24.0GB (75.1%), gpu_util=38.0%, loss=0.5486, ram=9.4/30.9GB (39.8%), samples/s=1404.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.5474, Train Acc: 0.8078, Train Throughput: 2165.49 samples/s | Val Loss: 0.2146, Val Acc: 0.9254, Val Throughput: 9099.89 samples/s | CPU Usage: 10.20% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 38.00% | GPU 0 Mem: 18.0/24.0GB (75.1%)\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2 = init_mobilenetv2_cifar10_model()\n",
    "cifar10_train_dataset, cifar10_val_dataset, cifar10_test_dataset = get_cifar10_datasets()\n",
    "\n",
    "# Adapt the MobileNetV2 model to CIFAR-10 dataset\n",
    "mobilenetv2_cifar10_baseline = adapt_model_head_to_dataset(\n",
    "    model=mobilenetv2,\n",
    "    train_dataset=cifar10_train_dataset,\n",
    "    val_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    head_train_epochs=5,  # Train head for fewer epochs\n",
    "    fine_tune_epochs=5,  # Fine-tune for fewer epochs\n",
    "    optimizer_cls=torch.optim.Adam,  # Use Adam optimizer\n",
    "    head_train_lr=0.001,  # Learning rate for head training\n",
    "    fine_tune_lr=0.0001,  # Learning rate for fine-tuning\n",
    "    use_amp=AMP_ENABLE,  # Use mixed precision training for efficiency\n",
    "    device=DEVICE, # Should be CUDA is available or CPU\n",
    "    dtype=DTYPE # Should be torch.float32 or torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 10:48:13,673 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.bfloat16, batch size: 64\n",
      "2025-06-12 10:48:13,676 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 11.21it/s]\n",
      "2025-06-12 10:48:14,211 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 79/79 [00:01<00:00, 43.85it/s, acc=0.9254, cpu=3.8%, gpu_mem=18.1/24.0GB (75.2%), gpu_util=39.0%, loss=0.5486, ram=9.4/30.9GB (39.8%), samples/s=1420.2]  \n",
      "2025-06-12 10:48:16,017 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.bfloat16, batch size: 64\n",
      "2025-06-12 10:48:16,020 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2146, Accuracy: 0.9254\n",
      "Throughput: 9594.24 samples/sec | Avg Batch Time: 6.60 ms | Avg Sample Time: 0.10 ms\n",
      "System Stats: CPU Usage: 13.40% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 39.00% | GPU 0 Mem: 18.1/24.0GB (75.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 14.10it/s]\n",
      "2025-06-12 10:48:16,472 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:03<00:00, 45.88it/s, acc=0.9288, cpu=2.7%, gpu_mem=18.0/24.0GB (75.2%), gpu_util=38.0%, loss=0.0395, ram=9.4/30.9GB (39.8%), samples/s=767.2]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2064, Accuracy: 0.9288\n",
      "Throughput: 9116.58 samples/sec | Avg Batch Time: 6.99 ms | Avg Sample Time: 0.11 ms\n",
      "System Stats: CPU Usage: 12.90% | RAM Usage: 9.1/30.9GB (38.9%) | GPU 0 Util: 38.00% | GPU 0 Mem: 18.0/24.0GB (75.2%)\n",
      "Validation accuracy of the adapted MobileNetV2 on CIFAR-10: 0.93\n",
      "Test accuracy of the adapted MobileNetV2 on CIFAR-10: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=AMP_ENABLE,\n",
    "    dtype=DTYPE\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=AMP_ENABLE,\n",
    "    dtype=DTYPE\n",
    ")\n",
    "print(f\"Validation accuracy of the adapted MobileNetV2 on CIFAR-10: {val_metrics['accuracy']:.2f}\")\n",
    "print(f\"Test accuracy of the adapted MobileNetV2 on CIFAR-10: {test_metrics['accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8406be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 10:48:22,315 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/model.pt\n",
      "2025-06-12 10:48:22,351 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Model state_dict saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/state_dict.pt\n",
      "2025-06-12 10:48:22,352 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Metadata saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/metadata.json\n",
      "2025-06-12 10:48:22,352 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Saving model in JIT script format...\n",
      "2025-06-12 10:48:22,623 - nnopt.recipes.mobilenetv2_cifar10 - INFO - JIT script model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/jit_script.pt\n",
      "2025-06-12 10:48:22,623 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Saving model in JIT trace format...\n",
      "2025-06-12 10:48:23,210 - nnopt.recipes.mobilenetv2_cifar10 - INFO - JIT model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/jit_trace.pt\n"
     ]
    }
   ],
   "source": [
    "# Export the adapted model\n",
    "save_mobilenetv2_cifar10_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    metrics_values={\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "    },\n",
    "    version=\"mobilenetv2_cifar10/fp32/baseline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471158d",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f1b30",
   "metadata": {},
   "source": [
    "## GPU FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157d5d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 10:48:27,638 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.float32, batch size: 64\n",
      "2025-06-12 10:48:27,669 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00,  7.88it/s]\n",
      "2025-06-12 10:48:28,401 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 79/79 [00:01<00:00, 43.78it/s, acc=0.9248, cpu=5.3%, gpu_mem=18.6/24.0GB (77.6%), gpu_util=60.0%, loss=0.5485, ram=9.5/30.9GB (40.2%), samples/s=531.4]  \n",
      "2025-06-12 10:48:30,210 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.float32, batch size: 64\n",
      "2025-06-12 10:48:30,213 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2172, Accuracy: 0.9248\n",
      "Throughput: 6371.58 samples/sec | Avg Batch Time: 9.93 ms | Avg Sample Time: 0.16 ms\n",
      "System Stats: CPU Usage: 11.60% | RAM Usage: 9.3/30.9GB (39.6%) | GPU 0 Util: 60.00% | GPU 0 Mem: 18.6/24.0GB (77.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 15.10it/s]\n",
      "2025-06-12 10:48:30,644 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:03<00:00, 46.19it/s, acc=0.9280, cpu=3.6%, gpu_mem=18.6/24.0GB (77.5%), gpu_util=56.0%, loss=0.0346, ram=9.5/30.9GB (40.2%), samples/s=1074.0] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2091, Accuracy: 0.9280\n",
      "Throughput: 6477.11 samples/sec | Avg Batch Time: 9.83 ms | Avg Sample Time: 0.15 ms\n",
      "System Stats: CPU Usage: 11.10% | RAM Usage: 9.3/30.9GB (39.6%) | GPU 0 Util: 56.00% | GPU 0 Mem: 18.6/24.0GB (77.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set on GPU\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=\"cuda\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=\"cuda\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bdf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Validation Metrics:\n",
      "accuracy: 0.9248\n",
      "avg_loss: 0.21724928364753723\n",
      "avg_time_per_batch: 0.009933343151853386\n",
      "avg_time_per_sample: 0.0001569468217992835\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 6371.584900769015\n",
      "\n",
      "- Test Metrics:\n",
      "accuracy: 0.928\n",
      "avg_loss: 0.20905147356987\n",
      "avg_time_per_batch: 0.009833745019248824\n",
      "avg_time_per_sample: 0.00015438979680220655\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 6477.111964083549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the val metrics\n",
    "import yaml\n",
    "print(\"- Validation Metrics:\")\n",
    "yaml_str = yaml.dump(val_metrics, default_flow_style=False)\n",
    "print(yaml_str)\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"- Test Metrics:\")\n",
    "yaml_str = yaml.dump(test_metrics, default_flow_style=False)\n",
    "print(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1417d7",
   "metadata": {},
   "source": [
    "## CPU FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959f1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 10:48:42,621 - nnopt.model.eval - INFO - Starting evaluation on device: cpu, dtype: torch.float32, batch size: 32\n",
      "2025-06-12 10:48:42,662 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:02<00:00,  2.50it/s]\n",
      "2025-06-12 10:48:44,761 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [01:05<00:00,  2.40it/s, acc=0.9248, cpu=46.6%, loss=0.5482, ram=9.6/30.9GB (41.7%), samples/s=163.4]\n",
      "2025-06-12 10:49:50,152 - nnopt.model.eval - INFO - Starting evaluation on device: cpu, dtype: torch.float32, batch size: 32\n",
      "2025-06-12 10:49:50,155 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2173, Accuracy: 0.9248\n",
      "Throughput: 85.90 samples/sec | Avg Batch Time: 370.74 ms | Avg Sample Time: 11.64 ms\n",
      "System Stats: CPU Usage: 15.10% | RAM Usage: 9.4/30.9GB (41.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:02<00:00,  2.21it/s]\n",
      "2025-06-12 10:49:52,525 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 313/313 [02:17<00:00,  2.27it/s, acc=0.9279, cpu=32.7%, loss=0.0346, ram=9.6/30.9GB (41.4%), samples/s=91.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2091, Accuracy: 0.9279\n",
      "Throughput: 80.13 samples/sec | Avg Batch Time: 398.73 ms | Avg Sample Time: 12.48 ms\n",
      "System Stats: CPU Usage: 16.00% | RAM Usage: 9.3/30.9GB (40.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set on CPU\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    device=\"cpu\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    device=\"cpu\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80077c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Validation Metrics:\n",
      "accuracy: 0.9248\n",
      "avg_loss: 0.21728209077119828\n",
      "avg_time_per_batch: 0.37074374931211085\n",
      "avg_time_per_sample: 0.011641353728400281\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 85.90066270045527\n",
      "\n",
      "- Test Metrics:\n",
      "accuracy: 0.9279\n",
      "avg_loss: 0.20908061562776564\n",
      "avg_time_per_batch: 0.3987278120160723\n",
      "avg_time_per_sample: 0.012480180516103064\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 80.1270461360482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the val metrics\n",
    "import yaml\n",
    "print(\"- Validation Metrics:\")\n",
    "yaml_str = yaml.dump(val_metrics, default_flow_style=False)\n",
    "print(yaml_str)\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"- Test Metrics:\")\n",
    "yaml_str = yaml.dump(test_metrics, default_flow_style=False)\n",
    "print(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f638e",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* Accuracy is ~92.8% for CIFAR-10 with MobileNetV2, with fast convergence for so few epochs.\n",
    "* GPU is ~75 time faster than CPU for both training and evaluation, which is to be expected considering architecture differences.\n",
    "* Thus, if wanting to run the model on a CPU for embedded cases, and expect high throughput during inference with little-to-no accuracy loss, the model should be optimised for the CPU. This can be done with pruning, quantization, knowledge distillation.\n",
    "* Pruning and quantization are good candidates and explored in the next notebooks, while knowledge distillation isn't because of the already efficient architecture of MobileNetV2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
