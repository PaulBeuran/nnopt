{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b634e",
   "metadata": {},
   "source": [
    "# 1. Data & Model Loading\n",
    "\n",
    "This notebook prepares the data and models used for the subsequent optimisation pipeline. This is to emulate a non-compressed model training and evaluation process, where the model is adapted to a specific dataset and then exported for further compression for embedded deployment.\n",
    "\n",
    "The process is defined as such:\n",
    "* A Torch dataset (already split into train and val) and model are loaded. Those must be specialized for classification tasks, but are agnostic\n",
    "of the modality.\n",
    "* The model\"s classification head is adapted to the number of classes in the dataset, trained on the training set while freezing the backbone, and evaluated on the validation set.\n",
    "* The whole model (backbone + classification head) is then adapted to the dataset by freezing all layers except the classification head, which is trained on the training set.\n",
    "* The adapted model is then exported as a Torch model for later use in the optimisation pipeline.\n",
    "\n",
    "An image MobileNetV2 model with a classification head adapted to the CIFAR-10 dataset is used as an example in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571044d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effcbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:08:11,693 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Using device: cuda, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from nnopt.model.train import adapt_model_head_to_dataset\n",
    "from nnopt.model.eval import eval_model\n",
    "from nnopt.model.const import DEVICE, DTYPE\n",
    "from nnopt.recipes.mobilenetv2_cifar10 import get_cifar10_datasets, save_mobilenetv2_cifar10_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a00783",
   "metadata": {},
   "source": [
    "# MobileNetV2 and CIFAR-10 adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75facaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:08:11,958 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading existing training and validation datasets...\n",
      "2025-06-11 14:08:16,984 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Loading existing test dataset...\n",
      "2025-06-11 14:08:17,552 - nnopt.model.train - INFO - Training head of the model with backbone frozen...\n",
      "Epoch 1/5 [Training]: 100%|██████████| 704/704 [00:38<00:00, 18.39it/s, acc=0.4703, cpu=4.7%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=39.0%, loss=1.4604, ram=10.6/30.9GB (46.2%), samples/s=343.6]  \n",
      "Epoch 1/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 41.51it/s, acc=0.6534, cpu=3.7%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=37.0%, loss=1.2511, ram=10.6/30.9GB (46.0%), samples/s=1364.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.5474, Train Acc: 0.4703, Train Throughput: 3663.66 samples/s | Val Loss: 1.0272, Val Acc: 0.6534, Val Throughput: 8299.74 samples/s | CPU Usage: 10.90% | RAM Usage: 10.4/30.9GB (45.4%) | GPU 0 Util: 37.00% | GPU 0 Mem: 16.0/24.0GB (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.86it/s, acc=0.5236, cpu=3.1%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=42.0%, loss=1.0861, ram=10.6/30.9GB (46.1%), samples/s=1045.5] \n",
      "Epoch 2/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 40.70it/s, acc=0.6734, cpu=0.0%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=39.0%, loss=1.3651, ram=10.6/30.9GB (46.2%), samples/s=1357.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 1.3628, Train Acc: 0.5236, Train Throughput: 3947.83 samples/s | Val Loss: 0.9437, Val Acc: 0.6734, Val Throughput: 8042.15 samples/s | CPU Usage: 10.20% | RAM Usage: 10.4/30.9GB (45.4%) | GPU 0 Util: 39.00% | GPU 0 Mem: 16.0/24.0GB (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.75it/s, acc=0.5315, cpu=2.7%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=41.0%, loss=1.0953, ram=10.6/30.9GB (46.1%), samples/s=948.5]  \n",
      "Epoch 3/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 41.51it/s, acc=0.6868, cpu=7.4%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=36.0%, loss=1.0769, ram=10.6/30.9GB (46.2%), samples/s=1398.0]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 1.3422, Train Acc: 0.5315, Train Throughput: 3870.97 samples/s | Val Loss: 0.9093, Val Acc: 0.6868, Val Throughput: 8096.54 samples/s | CPU Usage: 12.00% | RAM Usage: 10.4/30.9GB (45.4%) | GPU 0 Util: 36.00% | GPU 0 Mem: 16.0/24.0GB (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.73it/s, acc=0.5299, cpu=3.0%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=38.0%, loss=1.5663, ram=10.6/30.9GB (46.1%), samples/s=983.1]  \n",
      "Epoch 4/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 40.36it/s, acc=0.6782, cpu=0.0%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=39.0%, loss=1.0909, ram=10.6/30.9GB (46.2%), samples/s=1322.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 1.3366, Train Acc: 0.5299, Train Throughput: 3882.57 samples/s | Val Loss: 0.9252, Val Acc: 0.6782, Val Throughput: 7854.60 samples/s | CPU Usage: 11.30% | RAM Usage: 10.4/30.9GB (45.3%) | GPU 0 Util: 39.00% | GPU 0 Mem: 16.0/24.0GB (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.80it/s, acc=0.5319, cpu=3.0%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=36.0%, loss=1.3116, ram=10.6/30.9GB (46.2%), samples/s=1015.0] \n",
      "Epoch 5/5 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 40.55it/s, acc=0.7010, cpu=6.7%, gpu_mem=16.0/24.0GB (66.7%), gpu_util=42.0%, loss=1.0541, ram=10.6/30.9GB (46.2%), samples/s=1338.8] \n",
      "2025-06-11 14:11:27,873 - nnopt.model.train - INFO - Fine-tuning full model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.3340, Train Acc: 0.5319, Train Throughput: 3791.25 samples/s | Val Loss: 0.8776, Val Acc: 0.7010, Val Throughput: 7838.73 samples/s | CPU Usage: 11.00% | RAM Usage: 10.4/30.9GB (45.4%) | GPU 0 Util: 42.00% | GPU 0 Mem: 16.0/24.0GB (66.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.24it/s, acc=0.6450, cpu=4.6%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=67.0%, loss=1.3441, ram=10.7/30.9GB (46.3%), samples/s=158.5]  \n",
      "Epoch 1/3 [Validation]: 100%|██████████| 79/79 [00:02<00:00, 39.26it/s, acc=0.8524, cpu=3.8%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=36.0%, loss=0.6023, ram=10.7/30.9GB (46.5%), samples/s=1416.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 1.0127, Train Acc: 0.6450, Train Throughput: 2024.18 samples/s | Val Loss: 0.4233, Val Acc: 0.8524, Val Throughput: 8589.38 samples/s | CPU Usage: 10.70% | RAM Usage: 10.4/30.9GB (45.6%) | GPU 0 Util: 36.00% | GPU 0 Mem: 18.5/24.0GB (77.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Training]: 100%|██████████| 704/704 [00:36<00:00, 19.33it/s, acc=0.7209, cpu=3.2%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=46.0%, loss=0.9418, ram=10.7/30.9GB (46.5%), samples/s=474.8]  \n",
      "Epoch 2/3 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 40.72it/s, acc=0.8832, cpu=3.4%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=35.0%, loss=0.4247, ram=10.7/30.9GB (46.4%), samples/s=1326.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.7925, Train Acc: 0.7209, Train Throughput: 2029.49 samples/s | Val Loss: 0.3330, Val Acc: 0.8832, Val Throughput: 8807.78 samples/s | CPU Usage: 10.60% | RAM Usage: 10.4/30.9GB (45.6%) | GPU 0 Util: 34.00% | GPU 0 Mem: 18.5/24.0GB (77.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Training]: 100%|██████████| 704/704 [00:35<00:00, 19.63it/s, acc=0.7544, cpu=3.2%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=62.0%, loss=1.2642, ram=10.7/30.9GB (46.3%), samples/s=476.2]  \n",
      "Epoch 3/3 [Validation]: 100%|██████████| 79/79 [00:01<00:00, 40.39it/s, acc=0.8988, cpu=9.4%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=35.0%, loss=0.3132, ram=10.7/30.9GB (46.5%), samples/s=1263.4]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.7020, Train Acc: 0.7544, Train Throughput: 2041.14 samples/s | Val Loss: 0.2952, Val Acc: 0.8988, Val Throughput: 8442.85 samples/s | CPU Usage: 12.30% | RAM Usage: 10.4/30.9GB (45.6%) | GPU 0 Util: 35.00% | GPU 0 Mem: 18.5/24.0GB (77.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2 = torchvision.models.mobilenet_v2(\n",
    "    weights=torchvision.models.MobileNet_V2_Weights.DEFAULT\n",
    ")\n",
    "cifar10_train_dataset, cifar10_val_dataset, cifar10_test_dataset = get_cifar10_datasets()\n",
    "\n",
    "# Adapt the MobileNetV2 model to CIFAR-10 dataset\n",
    "mobilenetv2_cifar10_baseline = adapt_model_head_to_dataset(\n",
    "    model=mobilenetv2,\n",
    "    num_classes=10,  # CIFAR-10 has 10 classes\n",
    "    train_dataset=cifar10_train_dataset,\n",
    "    val_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    head_train_epochs=5,  # Train head for fewer epochs\n",
    "    fine_tune_epochs=3,  # Fine-tune for fewer epochs\n",
    "    optimizer_cls=torch.optim.Adam,  # Use Adam optimizer\n",
    "    head_train_lr=0.001,  # Learning rate for head training\n",
    "    fine_tune_lr=0.0001,  # Learning rate for fine-tuning\n",
    "    use_amp=True,  # Use mixed precision training\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb0b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:13:22,689 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.bfloat16, batch size: 64\n",
      "2025-06-11 14:13:22,693 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 12.82it/s]\n",
      "2025-06-11 14:13:23,170 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 79/79 [00:01<00:00, 40.67it/s, acc=0.8988, cpu=0.0%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=38.0%, loss=0.3132, ram=10.7/30.9GB (46.5%), samples/s=1359.7] \n",
      "2025-06-11 14:13:25,118 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.bfloat16, batch size: 64\n",
      "2025-06-11 14:13:25,121 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2952, Accuracy: 0.8988\n",
      "Throughput: 8822.51 samples/sec | Avg Batch Time: 7.17 ms | Avg Sample Time: 0.11 ms\n",
      "System Stats: CPU Usage: 10.90% | RAM Usage: 10.4/30.9GB (45.6%) | GPU 0 Util: 38.00% | GPU 0 Mem: 18.5/24.0GB (77.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 13.22it/s]\n",
      "2025-06-11 14:13:25,585 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:03<00:00, 42.22it/s, acc=0.9004, cpu=3.3%, gpu_mem=18.5/24.0GB (77.0%), gpu_util=40.0%, loss=0.0883, ram=10.7/30.9GB (46.6%), samples/s=629.3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2923, Accuracy: 0.9004\n",
      "Throughput: 8450.56 samples/sec | Avg Batch Time: 7.54 ms | Avg Sample Time: 0.12 ms\n",
      "System Stats: CPU Usage: 12.10% | RAM Usage: 10.5/30.9GB (45.7%) | GPU 0 Util: 26.00% | GPU 0 Mem: 18.5/24.0GB (77.0%)\n",
      "Validation accuracy of the adapted MobileNetV2 on CIFAR-10: 0.90\n",
      "Test accuracy of the adapted MobileNetV2 on CIFAR-10: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=True,\n",
    "    dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=DEVICE,\n",
    "    use_amp=True,\n",
    "    dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "print(f\"Validation accuracy of the adapted MobileNetV2 on CIFAR-10: {val_metrics['accuracy']:.2f}\")\n",
    "print(f\"Test accuracy of the adapted MobileNetV2 on CIFAR-10: {test_metrics['accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8406be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:13:29,367 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Metadata saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/metadata.json\n",
      "2025-06-11 14:13:29,368 - nnopt.recipes.mobilenetv2_cifar10 - INFO - Model saved to /home/pbeuran/repos/nnopt/models/mobilenetv2_cifar10/fp32/baseline/model.pt\n"
     ]
    }
   ],
   "source": [
    "# Export the adapted model\n",
    "save_mobilenetv2_cifar10_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    metrics_values={\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "    },\n",
    "    version=\"mobilenetv2_cifar10/fp32/baseline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471158d",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f1b30",
   "metadata": {},
   "source": [
    "## GPU FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157d5d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:13:29,373 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.float32, batch size: 64\n",
      "2025-06-11 14:13:29,377 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 10.75it/s]\n",
      "2025-06-11 14:13:29,933 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 79/79 [00:01<00:00, 40.64it/s, acc=0.8976, cpu=6.2%, gpu_mem=19.1/24.0GB (79.4%), gpu_util=56.0%, loss=0.3326, ram=10.8/30.9GB (46.7%), samples/s=477.1]  \n",
      "2025-06-11 14:13:31,882 - nnopt.model.eval - INFO - Starting evaluation on device: cuda, dtype: torch.float32, batch size: 64\n",
      "2025-06-11 14:13:31,885 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2991, Accuracy: 0.8976\n",
      "Throughput: 5888.79 samples/sec | Avg Batch Time: 10.75 ms | Avg Sample Time: 0.17 ms\n",
      "System Stats: CPU Usage: 11.40% | RAM Usage: 10.6/30.9GB (46.1%) | GPU 0 Util: 52.00% | GPU 0 Mem: 19.1/24.0GB (79.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:00<00:00, 13.16it/s]\n",
      "2025-06-11 14:13:32,356 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [00:03<00:00, 42.65it/s, acc=0.8981, cpu=3.4%, gpu_mem=19.0/24.0GB (79.4%), gpu_util=53.0%, loss=0.0930, ram=10.8/30.9GB (46.7%), samples/s=1008.3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2943, Accuracy: 0.8981\n",
      "Throughput: 6029.95 samples/sec | Avg Batch Time: 10.56 ms | Avg Sample Time: 0.17 ms\n",
      "System Stats: CPU Usage: 11.20% | RAM Usage: 10.6/30.9GB (46.1%) | GPU 0 Util: 53.00% | GPU 0 Mem: 19.0/24.0GB (79.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set on GPU\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=\"cuda\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    device=\"cuda\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4bdf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Validation Metrics:\n",
      "accuracy: 0.8976\n",
      "avg_loss: 0.2991045247554779\n",
      "avg_time_per_batch: 0.010747729316652204\n",
      "avg_time_per_sample: 0.00016981412320310482\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 5888.791704350515\n",
      "\n",
      "- Test Metrics:\n",
      "accuracy: 0.8981\n",
      "avg_loss: 0.2943320981144905\n",
      "avg_time_per_batch: 0.010562983795822151\n",
      "avg_time_per_sample: 0.00016583884559440775\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 6029.950319635612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the val metrics\n",
    "import yaml\n",
    "print(\"- Validation Metrics:\")\n",
    "yaml_str = yaml.dump(val_metrics, default_flow_style=False)\n",
    "print(yaml_str)\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"- Test Metrics:\")\n",
    "yaml_str = yaml.dump(test_metrics, default_flow_style=False)\n",
    "print(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1417d7",
   "metadata": {},
   "source": [
    "## CPU FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959f1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:13:36,081 - nnopt.model.eval - INFO - Starting evaluation on device: cpu, dtype: torch.float32, batch size: 32\n",
      "2025-06-11 14:13:36,116 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n",
      "[Warmup]: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n",
      "2025-06-11 14:13:38,684 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 157/157 [01:06<00:00,  2.35it/s, acc=0.8970, cpu=47.4%, loss=0.3332, ram=10.9/30.9GB (48.1%), samples/s=169.1]\n",
      "2025-06-11 14:14:45,357 - nnopt.model.eval - INFO - Starting evaluation on device: cpu, dtype: torch.float32, batch size: 32\n",
      "2025-06-11 14:14:45,360 - nnopt.model.eval - INFO - Starting warmup for 5 batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2994, Accuracy: 0.8970\n",
      "Throughput: 77.05 samples/sec | Avg Batch Time: 413.32 ms | Avg Sample Time: 12.98 ms\n",
      "System Stats: CPU Usage: 15.50% | RAM Usage: 10.7/30.9GB (47.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Warmup]: 100%|██████████| 5/5 [00:02<00:00,  1.75it/s]\n",
      "2025-06-11 14:14:48,317 - nnopt.model.eval - INFO - Warmup complete.\n",
      "[Evaluation]: 100%|██████████| 313/313 [02:30<00:00,  2.08it/s, acc=0.8979, cpu=48.7%, loss=0.0928, ram=10.8/30.9GB (47.5%), samples/s=68.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete: Avg Loss: 0.2946, Accuracy: 0.8979\n",
      "Throughput: 67.92 samples/sec | Avg Batch Time: 470.42 ms | Avg Sample Time: 14.72 ms\n",
      "System Stats: CPU Usage: 34.50% | RAM Usage: 10.6/30.9GB (46.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the adapted model on the validation and test set on CPU\n",
    "val_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_val_dataset,\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    device=\"cpu\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "test_metrics = eval_model(\n",
    "    model=mobilenetv2_cifar10_baseline,\n",
    "    test_dataset=cifar10_test_dataset,\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    device=\"cpu\",\n",
    "    use_amp=False,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80077c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Validation Metrics:\n",
      "accuracy: 0.897\n",
      "avg_loss: 0.2993665291070938\n",
      "avg_time_per_batch: 0.41331771221001684\n",
      "avg_time_per_sample: 0.012978176163394528\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 77.0524292019198\n",
      "\n",
      "- Test Metrics:\n",
      "accuracy: 0.8979\n",
      "avg_loss: 0.2945516872644424\n",
      "avg_time_per_batch: 0.4704234021278193\n",
      "avg_time_per_sample: 0.014724252486600744\n",
      "params_stats:\n",
      "  approx_memory_mb_for_params: 8.532264709472656\n",
      "  bn_param_params: 34112\n",
      "  float_bias_params: 10\n",
      "  float_weight_params: 2202560\n",
      "  int_weight_params: 0\n",
      "  other_float_params: 0\n",
      "  total_params: 2236682\n",
      "samples_per_second: 67.91516247836776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the val metrics\n",
    "import yaml\n",
    "print(\"- Validation Metrics:\")\n",
    "yaml_str = yaml.dump(val_metrics, default_flow_style=False)\n",
    "print(yaml_str)\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"- Test Metrics:\")\n",
    "yaml_str = yaml.dump(test_metrics, default_flow_style=False)\n",
    "print(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f638e",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* Accuracy is ~90% for CIFAR-10 with MobileNetV2, with fast convergence for so few epochs.\n",
    "* GPU is ~100x time faster than CPU for both training and evaluation, which is to be expected considering architecture differences.\n",
    "* Thus, if wanting to run the model on a CPU for embedded cases, and expect high throughput during inference with little-to-no accuracy loss, the model should be optimised for the CPU. This can be done with pruning, quantization, knowledge distillation.\n",
    "* Pruning and quantization are good candidates and explored in the next notebooks, while knowledge distillation isn't because of the already efficient architecture of MobileNetV2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
